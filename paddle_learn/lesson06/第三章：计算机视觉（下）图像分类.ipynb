{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像分类是根据图像的语义信息对不同类别图像进行区分，是计算机视觉的核心，是物体检测、图像分割、物体跟踪、行为分析、人脸识别等其他高层次视觉任务的基础。图像分类在许多领域都有着广泛的应用，如：安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。\n",
    "\n",
    "上一节主要介绍了卷积神经网络常用的一些基本模块，本节将基于眼疾分类数据集iChallenge-PM，对图像分类领域的经典卷积神经网络进行剖析，介绍如何应用这些基础模块构建卷积神经网络，解决图像分类问题。按照被提出的时间顺序，涵盖如下卷积神经网络：\n",
    "\n",
    "- LeNet：Yan LeCun等人于1998年第一次将卷积神经网络应用到图像分类任务上[1]，在手写数字识别任务上取得了巨大成功。\n",
    "\n",
    "- AlexNet：Alex Krizhevsky等人在2012年提出了AlexNet[2], 并应用在大尺寸图片数据集ImageNet上，获得了2012年ImageNet比赛冠军(ImageNet Large Scale Visual Recognition Challenge，ILSVRC）。\n",
    "\n",
    "- VGG：Simonyan和Zisserman于2014年提出了VGG网络结构[3]，是当前最流行的卷积神经网络之一，由于其结构简单、应用性极强而深受广大研究者欢迎。\n",
    "\n",
    "- GoogLeNet：Christian Szegedy等人在2014提出了GoogLeNet[4]，并取得了2014年ImageNet比赛冠军。\n",
    "\n",
    "- ResNet：Kaiming He等人在2015年提出了ResNet[5]，通过引入残差模块加深网络层数，在ImagNet数据集上的错误率降低到3.6%，超越了人眼识别水平。ResNet的设计思想深刻地影响了后来的深度神经网络的设计。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "\n",
    "LeNet是最早的卷积神经网络之一[1]。1998年，Yann LeCun第一次将LeNet卷积神经网络应用到图像分类上，在手写数字识别任务中取得了巨大成功。LeNet通过连续使用卷积和池化层的组合提取图像特征，其架构如 **图1** 所示，这里展示的是用于MNIST手写体数字识别任务中的LeNet-5模型：\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/82e4124e2e6a4231bcde17e086bc86ba732d3e81dcd7415f86fb4ef050aa7772\" width = \"800\"></center>\n",
    "<center><br>图1：LeNet模型网络结构示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "* 第一模块：包含5×5的6通道卷积和2×2的池化。卷积提取图像中包含的特征模式（激活函数使用Sigmoid），图像尺寸从28减小到24。经过池化层可以降低输出特征图对空间位置的敏感性，图像尺寸减到12。\n",
    "\n",
    "* 第二模块：和第一模块尺寸相同，通道数由6增加为16。卷积操作使图像尺寸减小到8，经过池化后变成4。\n",
    "\n",
    "* 第三模块：包含4×4的120通道卷积。卷积之后的图像尺寸减小到1，但是通道数增加为120。将经过第3次卷积提取到的特征图输入到全连接层。第一个全连接层的输出神经元的个数是64，第二个全连接层的输出神经元个数是分类标签的类别数，对于手写数字识别的类别数是10。然后使用Softmax激活函数即可计算出每个类别的预测概率。\n",
    "\n",
    "------\n",
    "**【提示】：**\n",
    "\n",
    "卷积层的输出特征图如何当作全连接层的输入使用呢？\n",
    "\n",
    "卷积层的输出数据格式是$[N, C, H, W]$，在输入全连接层的时候，会自动将数据拉平，\n",
    "\n",
    "也就是对每个样本，自动将其转化为长度为$K$的向量，\n",
    "\n",
    "其中$K = C \\times H \\times W$，一个mini-batch的数据维度变成了$N\\times K$的二维向量。\n",
    "\n",
    "------\n",
    "\n",
    "## LeNet在手写数字识别上的应用\n",
    "\n",
    "LeNet网络的实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import paddle\n",
    "import numpy as np\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "\n",
    "## 组网\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(paddle.nn.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 创建卷积和池化层\n",
    "        # 创建第1个卷积层\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 尺寸的逻辑：池化层未改变通道数；当前通道数为6\n",
    "        # 创建第2个卷积层\n",
    "        self.conv2 = Conv2D(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(in_channels=16, out_channels=120, kernel_size=4)\n",
    "        # 尺寸的逻辑：输入层将数据拉平[B,C,H,W] -> [B,C*H*W]\n",
    "        # 输入size是[28,28]，经过三次卷积和两次池化之后，C*H*W等于120\n",
    "        self.fc1 = Linear(in_features=120, out_features=64)\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64， 第二个全连接层输出神经元个数为分类标签的类别数\n",
    "        self.fc2 = Linear(in_features=64, out_features=num_classes)\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # 每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        # 尺寸的逻辑：输入层将数据拉平[B,C,H,W] -> [B,C*H*W]\n",
    "        x = paddle.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "飞桨会根据实际图像数据的尺寸和卷积核参数自动推断中间层数据的W和H等，只需要用户表达通道数即可。下面的程序使用随机数作为输入，查看经过LeNet-5的每一层作用之后，输出数据的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0116 16:55:20.589471 556572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.3, Runtime API Version: 12.0\n",
      "W0116 16:55:20.590859 556572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2D(1, 6, kernel_size=[5, 5], data_format=NCHW), MaxPool2D(kernel_size=2, stride=2, padding=0), Conv2D(6, 16, kernel_size=[5, 5], data_format=NCHW), MaxPool2D(kernel_size=2, stride=2, padding=0), Conv2D(16, 120, kernel_size=[4, 4], data_format=NCHW), Linear(in_features=120, out_features=64, dtype=float32), Linear(in_features=64, out_features=10, dtype=float32)]\n",
      "conv2d_0 [3, 6, 24, 24] [6, 1, 5, 5] [6]\n",
      "max_pool2d_0 [3, 6, 12, 12]\n",
      "conv2d_1 [3, 16, 8, 8] [16, 6, 5, 5] [16]\n",
      "max_pool2d_1 [3, 16, 4, 4]\n",
      "conv2d_2 [3, 120, 1, 1] [120, 16, 4, 4] [120]\n",
      "linear_0 [3, 64] [120, 64] [64]\n",
      "linear_1 [3, 10] [64, 10] [10]\n"
     ]
    }
   ],
   "source": [
    "# 输入数据形状是 [N, 1, H, W]\n",
    "# 这里用np.random创建一个随机数组作为输入数据\n",
    "x = np.random.randn(*[3,1,28,28])\n",
    "x = x.astype('float32')\n",
    "\n",
    "# 创建LeNet类的实例，指定模型名称和分类的类别数目\n",
    "model = LeNet(num_classes=10)\n",
    "# 通过调用LeNet从基类继承的sublayers()函数，\n",
    "# 查看LeNet中所包含的子层\n",
    "print(model.sublayers())\n",
    "x = paddle.to_tensor(x)\n",
    "for item in model.sublayers():\n",
    "    # item是LeNet类中的一个子层\n",
    "    # 查看经过子层之后的输出数据形状\n",
    "    try:\n",
    "        x = item(x)\n",
    "    except:\n",
    "        x = paddle.reshape(x, [x.shape[0], -1])\n",
    "        x = item(x)\n",
    "    if len(item.parameters())==2:\n",
    "        # 查看卷积和全连接层的数据和参数的形状，\n",
    "        # 其中item.parameters()[0]是权重参数w，item.parameters()[1]是偏置参数b\n",
    "        print(item.full_name(), x.shape, item.parameters()[0].shape, item.parameters()[1].shape)\n",
    "    else:\n",
    "        # 池化层没有参数\n",
    "        print(item.full_name(), x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积Conv2D的padding参数默认为0，stride参数默认为1，当输入形状为[Bx1x28x28]时，B是batch_size，经过第一层卷积（kernel_size=5, out_channels=6）和maxpool之后，得到形状为[Bx6x12x12]的特征图；经过第二层卷积(kernel_size=5, out_channels=16)和maxpool之后，得到形状为[Bx16x4x4]的特征图；经过第三层卷积(out_channels=120, kernel_size=4)之后，得到形状为[Bx120x1x1]的特征图，在FC层计算之前，将输入特征从卷积得到的四维特征reshape到格式为[B, 120x1x1]的特征，这也是LeNet中第一层全连接层输入shape为120的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n",
      "epoch: 0, batch_id: 0, loss is: 2.5735\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# LeNet 识别手写数字\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.vision.transforms import ToTensor\n",
    "from paddle.vision.datasets import MNIST\n",
    "\n",
    "# 定义训练过程\n",
    "def train(model, opt, train_loader, valid_loader):\n",
    "    # 开启0号GPU训练\n",
    "    use_gpu = True\n",
    "    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            img = data[0]\n",
    "            label = data[1] \n",
    "            # 计算模型输出\n",
    "            logits = model(img)\n",
    "            # 计算损失函数\n",
    "            loss_func = paddle.nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = loss_func(logits, label)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 2000 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {:.4f}\".format(epoch, batch_id, float(avg_loss.numpy())))\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            img = data[0]\n",
    "            label = data[1] \n",
    "            # 计算模型输出\n",
    "            logits = model(img)\n",
    "            pred = F.softmax(logits)\n",
    "            # 计算损失函数\n",
    "            loss_func = paddle.nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = loss_func(logits, label)\n",
    "            acc = paddle.metric.accuracy(pred, label)\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "        print(\"[validation] accuracy/loss: {:.4f}/{:.4f}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "        model.train()\n",
    "\n",
    "    # 保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "\n",
    "\n",
    "# 创建模型\n",
    "model = LeNet(num_classes=10)\n",
    "# 设置迭代轮数\n",
    "EPOCH_NUM = 5\n",
    "# 设置优化器为Momentum，学习率为0.001\n",
    "opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters())\n",
    "# 定义数据读取器\n",
    "train_loader = paddle.io.DataLoader(MNIST(mode='train', transform=ToTensor()), batch_size=10, shuffle=True)\n",
    "valid_loader = paddle.io.DataLoader(MNIST(mode='test', transform=ToTensor()), batch_size=10)\n",
    "# 启动训练过程\n",
    "train(model, opt, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过运行结果可以看出，LeNet在手写数字识别MNIST验证数据集上的准确率高达92%以上。那么对于其它数据集效果如何呢？我们通过眼疾识别数据集iChallenge-PM验证一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet在眼疾识别数据集iChallenge-PM上的应用\n",
    "\n",
    "[iChallenge-PM](https://ai.baidu.com/broad/introduction)是百度大脑和中山大学中山眼科中心联合举办的iChallenge比赛中，提供的关于病理性近视（Pathologic Myopia，PM）的医疗类数据集，包含1200个受试者的眼底视网膜图片，训练、验证和测试数据集各400张。下面我们详细介绍LeNet在iChallenge-PM上的训练过程。\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "如今近视已经成为困扰人们健康的一项全球性负担，在近视人群中，有超过35%的人患有重度近视。近视会拉长眼睛的光轴，也可能引起视网膜或者络网膜的病变。随着近视度数的不断加深，高度近视有可能引发病理性病变，这将会导致以下几种症状：视网膜或者络网膜发生退化、视盘区域萎缩、漆裂样纹损害、Fuchs斑等。因此，及早发现近视患者眼睛的病变并采取治疗，显得非常重要。\n",
    "\n",
    "数据可以从AI Studio[下载](https://aistudio.baidu.com/aistudio/datasetdetail/19065)\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备\n",
    "\n",
    "/home/aistudio/data/data19065 目录包括如下三个文件，解压缩后存放在/home/aistudio/work/palm目录下。\n",
    "- training.zip：包含训练中的图片和标签\n",
    "- validation.zip：包含验证集的图片\n",
    "- valid_gt.zip：包含验证集的标签\n",
    "\n",
    "------\n",
    "**注意**：\n",
    "\n",
    "valid_gt.zip文件解压缩之后，需要将“/home/aistudio/work/palm/PALM-Validation-GT/”目录下的“PM_Label_and_Fovea_Location.xlsx”文件转存成.csv格式，本节代码示例中已经提前转成文件labels.csv。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 初次运行时将注释取消，以便解压文件\n",
    "# 如果已经解压过，不需要运行此段代码，否则由于文件已经存在，解压时会报错\n",
    "!unzip -o -q -d /home/aistudio/work/palm /root/codes/ocr/paddle-ocr-learn/paddle_learn/lesson11/data/training.zip\n",
    "%cd /home/aistudio/work/palm/PALM-Training400/\n",
    "!unzip -o -q PALM-Training400.zip\n",
    "!unzip -o -q -d /home/aistudio/work/palm /root/codes/ocr/paddle-ocr-learn/paddle_learn/lesson11/data/validation.zip\n",
    "!unzip -o -q -d /home/aistudio/work/palm /root/codes/ocr/paddle-ocr-learn/paddle_learn/lesson11/data/valid_gt.zip\n",
    "#返回家目录，生成模型文件位于/home/aistudio/\n",
    "%cd /home/aistudio/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看数据集图片\n",
    "\n",
    "iChallenge-PM中既有病理性近视患者的眼底图片，也有非病理性近视患者的图片，命名规则如下：\n",
    "\n",
    "- 病理性近视（PM）：文件名以P开头\n",
    "\n",
    "- 非病理性近视（non-PM）：\n",
    "\n",
    "  * 高度近视（high myopia）：文件名以H开头\n",
    "  \n",
    "  * 正常眼睛（normal）：文件名以N开头\n",
    "\n",
    "我们将病理性患者的图片作为正样本，标签为1； 非病理性患者的图片作为负样本，标签为0。从数据集中选取两张图片，通过LeNet提取特征，构建分类器，对正负样本进行分类，并将图片显示出来。代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "# 文件名以N开头的是正常眼底图片，以P开头的是病变眼底图片\n",
    "file1 = 'N0012.jpg'\n",
    "file2 = 'P0095.jpg'\n",
    "\n",
    "# 读取图片\n",
    "img1 = Image.open(os.path.join(DATADIR, file1))\n",
    "img1 = np.array(img1)\n",
    "img2 = Image.open(os.path.join(DATADIR, file2))\n",
    "img2 = np.array(img2)\n",
    "\n",
    "# 画出读取的图片\n",
    "plt.figure(figsize=(16, 8))\n",
    "f = plt.subplot(121)\n",
    "f.set_title('Normal', fontsize=20)\n",
    "plt.imshow(img1)\n",
    "f = plt.subplot(122)\n",
    "f.set_title('PM', fontsize=20)\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 查看图片形状\n",
    "img1.shape, img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义数据读取器\n",
    "\n",
    "使用OpenCV从磁盘读入图片，将每张图缩放到$224\\times224$大小，并且将像素值调整到$[-1, 1]$之间，代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 对读入的图像数据进行预处理\n",
    "def transform_img(img):\n",
    "    # 将图片尺寸缩放道 224x224\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    # 读入的图像数据格式是[H, W, C]\n",
    "    # 使用转置操作将其变成[C, H, W]\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = img.astype('float32')\n",
    "    # 将数据范围调整到[-1.0, 1.0]之间\n",
    "    img = img / 255.\n",
    "    img = img * 2.0 - 1.0\n",
    "    return img\n",
    "\n",
    "# 定义训练集数据读取器\n",
    "def data_loader(datadir, batch_size=10, mode = 'train'):\n",
    "    # 将datadir目录下的文件列出来，每条文件都要读入\n",
    "    filenames = os.listdir(datadir)\n",
    "    def reader():\n",
    "        if mode == 'train':\n",
    "            # 训练时随机打乱数据顺序\n",
    "            random.shuffle(filenames)\n",
    "        batch_imgs = []\n",
    "        batch_labels = []\n",
    "        for name in filenames:\n",
    "            filepath = os.path.join(datadir, name)\n",
    "            img = cv2.imread(filepath)\n",
    "            img = transform_img(img)\n",
    "            if name[0] == 'H' or name[0] == 'N':\n",
    "                # H开头的文件名表示高度近似，N开头的文件名表示正常视力\n",
    "                # 高度近视和正常视力的样本，都不是病理性的，属于负样本，标签为0\n",
    "                label = 0\n",
    "            elif name[0] == 'P':\n",
    "                # P开头的是病理性近视，属于正样本，标签为1\n",
    "                label = 1\n",
    "            else:\n",
    "                raise('Not excepted file name')\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\n",
    "            batch_imgs.append(img)\n",
    "            batch_labels.append(label)\n",
    "            if len(batch_imgs) == batch_size:\n",
    "                # 当数据列表的长度等于batch_size的时候，\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "                yield imgs_array, labels_array\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "\n",
    "        if len(batch_imgs) > 0:\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "            yield imgs_array, labels_array\n",
    "\n",
    "    return reader\n",
    "\n",
    "# 定义验证集数据读取器\n",
    "def valid_data_loader(datadir, csvfile, batch_size=10, mode='valid'):\n",
    "    # 训练集读取时通过文件名来确定样本标签，验证集则通过csvfile来读取每个图片对应的标签\n",
    "    # 请查看解压后的验证集标签数据，观察csvfile文件里面所包含的内容\n",
    "    # csvfile文件所包含的内容格式如下，每一行代表一个样本，\n",
    "    # 其中第一列是图片id，第二列是文件名，第三列是图片标签，\n",
    "    # 第四列和第五列是Fovea的坐标，与分类任务无关\n",
    "    # ID,imgName,Label,Fovea_X,Fovea_Y\n",
    "    # 1,V0001.jpg,0,1157.74,1019.87\n",
    "    # 2,V0002.jpg,1,1285.82,1080.47\n",
    "    # 打开包含验证集标签的csvfile，并读入其中的内容\n",
    "    filelists = open(csvfile).readlines()\n",
    "    def reader():\n",
    "        batch_imgs = []\n",
    "        batch_labels = []\n",
    "        for line in filelists[1:]:\n",
    "            line = line.strip().split(',')\n",
    "            name = line[1]\n",
    "            label = int(line[2])\n",
    "            # 根据图片文件名加载图片，并对图像数据作预处理\n",
    "            filepath = os.path.join(datadir, name)\n",
    "            img = cv2.imread(filepath)\n",
    "            img = transform_img(img)\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\n",
    "            batch_imgs.append(img)\n",
    "            batch_labels.append(label)\n",
    "            if len(batch_imgs) == batch_size:\n",
    "                # 当数据列表的长度等于batch_size的时候，\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "                yield imgs_array, labels_array\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "\n",
    "        if len(batch_imgs) > 0:\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "            yield imgs_array, labels_array\n",
    "\n",
    "    return reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 查看数据形状\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "train_loader = data_loader(DATADIR, \n",
    "                           batch_size=10, mode='train')\n",
    "data_reader = train_loader()\n",
    "data = next(data_reader)\n",
    "data[0].shape, data[1].shape\n",
    "\n",
    "eval_loader = data_loader(DATADIR, \n",
    "                           batch_size=10, mode='eval')\n",
    "data_reader = eval_loader()\n",
    "data = next(data_reader)\n",
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# LeNet 识别眼疾图片\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import numpy as np\n",
    "\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "DATADIR2 = '/home/aistudio/work/palm/PALM-Validation400'\n",
    "CSVFILE = '/home/aistudio/labels.csv'\n",
    "# 设置迭代轮数\n",
    "EPOCH_NUM = 5\n",
    "\n",
    "# 定义训练过程\n",
    "def train_pm(model, optimizer):\n",
    "    # 开启0号GPU训练\n",
    "    use_gpu = True\n",
    "    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')\n",
    "\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "    # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "    train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "    valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = paddle.to_tensor(x_data)\n",
    "            label = paddle.to_tensor(y_data)\n",
    "            # 运行模型前向计算，得到预测值\n",
    "            logits = model(img)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 20 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {:.4f}\".format(epoch, batch_id, float(avg_loss.numpy())))\n",
    "            # 反向传播，更新权重，清除梯度\n",
    "            avg_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = paddle.to_tensor(x_data)\n",
    "            label = paddle.to_tensor(y_data)\n",
    "            # 运行模型前向计算，得到预测值\n",
    "            logits = model(img)\n",
    "            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "            # 计算sigmoid后的预测概率，进行loss计算\n",
    "            pred = F.sigmoid(logits)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "            # 计算预测概率小于0.5的类别\n",
    "            pred2 = pred * (-1.0) + 1.0\n",
    "            # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "            pred = paddle.concat([pred2, pred], axis=1)\n",
    "            acc = paddle.metric.accuracy(pred, paddle.cast(label, dtype='int64'))\n",
    "\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "        print(\"[validation] accuracy/loss: {:.4f}/{:.4f}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "        model.train()\n",
    "\n",
    "        paddle.save(model.state_dict(), 'palm.pdparams')\n",
    "        paddle.save(optimizer.state_dict(), 'palm.pdopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 定义评估过程\n",
    "def evaluation(model, params_file_path):\n",
    "\n",
    "    # 开启0号GPU预估\n",
    "    use_gpu = True\n",
    "    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')\n",
    "\n",
    "    print('start evaluation .......')\n",
    "\n",
    "    #加载模型参数\n",
    "    model_state_dict = paddle.load(params_file_path)\n",
    "    model.load_dict(model_state_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = data_loader(DATADIR, \n",
    "                        batch_size=10, mode='eval')\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        x_data, y_data = data\n",
    "        img = paddle.to_tensor(x_data)\n",
    "        label = paddle.to_tensor(y_data)\n",
    "        y_data = y_data.astype(np.int64)\n",
    "        label_64 = paddle.to_tensor(y_data)\n",
    "        # 计算预测和精度\n",
    "        prediction, acc = model(img, label_64)\n",
    "        # 计算损失函数值\n",
    "        loss = F.binary_cross_entropy_with_logits(prediction, label)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    # 求平均精度\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={:.4f}, acc={:.4f}'.format(avg_loss_val_mean, acc_val_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# 导入需要的包\n",
    "import paddle\n",
    "import numpy as np\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear, Dropout\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(paddle.nn.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        self.conv2 = Conv2D(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(in_channels=16, out_channels=120, kernel_size=4)\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64\n",
    "        self.fc1 = Linear(in_features=300000, out_features=64)\n",
    "        # 第二个全连接层输出神经元个数为分类标签的类别数\n",
    "        self.fc2 = Linear(in_features=64, out_features=num_classes)\n",
    "\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x, label=None):\n",
    "        x = self.conv1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = paddle.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        if label is not None:\n",
    "            if self.num_classes == 1:\n",
    "                pred = F.sigmoid(x)\n",
    "                pred = paddle.concat([1.0 - pred, pred], axis=1)\n",
    "                acc = paddle.metric.accuracy(pred, paddle.cast(label, dtype='int64'))\n",
    "            else:\n",
    "                acc = paddle.metric.accuracy(x, paddle.cast(label, dtype='int64'))\n",
    "            return x, acc\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比本章最初定义的LeNet，发现两个LeNet的第一层全连接层的输入特征维度不同，一个是120，一个是30000。这个不同是输入数据的形状不同引起的，手写字符识别的图像输入形状比较小，第三层卷积之前的特征维度是[B, 120x1x1]，但是PALM数据的输入数据形状较大，形状为[B, 120x50x50]，120x50x50等于300000，所以不同的输入大小，会影响卷积后全连接层的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = LeNet(num_classes=1)\n",
    "# 启动训练过程\n",
    "opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters())\n",
    "train_pm(model, optimizer=opt)\n",
    "evaluation(model, params_file_path=\"palm.pdparams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过运行结果可以看出，在眼疾筛查数据集iChallenge-PM上，LeNet的loss很难下降，模型没有收敛。这是因为MNIST数据集的图片尺寸比较小（$28\\times28$），但是眼疾筛查数据集图片尺寸比较大（原始图片尺寸约为$2000 \\times 2000$，经过缩放之后变成$224 \\times 224$），LeNet模型很难进行有效分类。这说明在图片尺寸比较大时，LeNet在图像分类任务上存在局限性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用飞桨高层API直接调用图像分类网络\n",
    "\n",
    "飞桨开源框架2.0版本支持全新升级的API体系，除了基础API外，还支持了高层API。通过高低融合实现灵活组网，让飞桨API更简洁、更易用、更强大。高层API支持paddle.vision.models接口，实现了对常用模型的封装，包括ResNet、VGG、MobileNet、LeNet等。使用高层API调用这些网络，可以快速完成神经网络的训练和Fine-tune。\n",
    "\n",
    "代码示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0116 17:27:46.264245 556735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.3, Runtime API Version: 12.0\n",
      "W0116 17:27:46.265535 556735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/norm.py:824: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1000]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.vision.models import resnet50\n",
    "\n",
    "# 调用高层API的resnet50模型\n",
    "model = resnet50()\n",
    "# 设置pretrained参数为True，可以加载resnet50在imagenet数据集上的预训练模型\n",
    "# model = resnet50(pretrained=True)\n",
    "\n",
    "# 随机生成一个输入\n",
    "x = paddle.rand([1, 3, 224, 224])\n",
    "# 得到残差50的计算结果\n",
    "out = model(x)\n",
    "# 打印输出的形状，由于resnet50默认的是1000分类\n",
    "# 所以输出shape是[1x1000]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用paddle.vision中的模型可以简单快速的构建一个深度学习任务，如下示例，仅14行代码即可实现resnet在Cifar10数据集上的训练。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddleSeg动态图API使用教程\n",
    "\n",
    "本教程旨在帮助大家快速掌握PaddleSeg的API调用，轻松进行语义分割模型的训练、验证和预测。\n",
    "\n",
    "如果对配置化调用方式更感兴趣，可参考[快速上手PaddleSeg文档](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.7/docs/whole_process_cn.md)。\n",
    "\n",
    "Note：\n",
    "* 请在AI studio上fork本项目的最新版本，然后运行使用。\n",
    "* 若想更详细地了解PaddleSeg API，请阅读[API文档](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.7/docs/apis/README_CN.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/codes/ocr/paddle-ocr-learn/paddle_learn/lesson09/PaddleSeg\n"
     ]
    }
   ],
   "source": [
    "%cd /root/codes/ocr/paddle-ocr-learn/paddle_learn/lesson09/PaddleSeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、环境准备\n",
    "\n",
    "**PaddlePaddle环境准备**\n",
    "\n",
    "如果在AI Studio上运行此项目，请选择使用GPU版本的环境，默认已经安装了PaddlePaddle。\n",
    "    \n",
    "如果在本地运行此教程，需要自行安装PaddlePaddle。\n",
    "由于图像分割模型计算开销大，建议在GPU版本的PaddlePaddle下使用PaddleSeg，安装教程请见[PaddlePaddle官网](https://www.paddlepaddle.org.cn/)。推荐：\n",
    "* PaddlePaddle （最新版本）\n",
    "* Python = 3.7\n",
    "\n",
    "**PaddleSeg环境准备**\n",
    "\n",
    "安装过程请参考[PaddleSeg安装文档](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.7/docs/install_cn.md)，下面进行安装："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、模型训练、验证和预测\n",
    "\n",
    "本教程使用PP_LiteSeg模型在视盘分割数据集上基于API进行开发。\n",
    "\n",
    "\n",
    "## 2.1 模型训练\n",
    "\n",
    "使用API进行训练的过程可分为五步，分别是构建模型、构建训练集与验证集、构建优化器、构建损失函数和启动训练。\n",
    "\n",
    "### 构建模型\n",
    "\n",
    "PaddleSeg在paddleseg.models子模块中提供了常用的分割模型，在paddleseg.models.backbones子模块中提供了分割模型常用的骨干网络，大家可以直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:09:13 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/PP_STDCNet1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0213 20:09:13.637141 978575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.2, Runtime API Version: 12.0\n",
      "W0213 20:09:13.638809 978575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://bj.bcebos.com/paddleseg/dygraph/PP_STDCNet1.tar.gz\n",
      "Downloading PP_STDCNet1.tar.gz\n",
      "[==================================================] 100.00%\n",
      "Uncompress PP_STDCNet1.tar.gz\n",
      "[==================================================] 100.00%\n",
      "2024-02-13 20:09:17 [INFO]\tThere are 145/145 variables loaded into STDCNet.\n"
     ]
    }
   ],
   "source": [
    "from paddleseg.models import PPLiteSeg\n",
    "from paddleseg.models.backbones import STDC1\n",
    "model = PPLiteSeg(\n",
    "    num_classes=2, # 背景+前景类别数\n",
    "    backbone=STDC1(pretrained='https://bj.bcebos.com/paddleseg/dygraph/PP_STDCNet1.tar.gz')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建训练集与验证集\n",
    "\n",
    "PaddleSeg在paddleseg.transforms子模块中提供了常用的数据预处理操作，需要注意的是PaddleSeg默认会添加读取图像操作、HWC转CHW的操作，所以这两个操作不用添加到transforms列表中。\n",
    "\n",
    "在paddleseg.datasets子模块中提供了分割常用的数据集构建API，也支持符合格式的[自定义数据集](https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.7/docs/data/marker/marker_cn.md)，本教程使用的是子模块提供的数据集API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://paddleseg.bj.bcebos.com/dataset/optic_disc_seg.zip\n",
      "Downloading optic_disc_seg.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress optic_disc_seg.zip\n",
      "[==================================================] 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 训练集预处理操作\n",
    "import paddleseg.transforms as T\n",
    "train_transforms = [\n",
    "    T.Resize(target_size=(512, 512)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.Normalize()\n",
    "]\n",
    "\n",
    "# 构建训练集\n",
    "from paddleseg.datasets import OpticDiscSeg\n",
    "train_dataset = OpticDiscSeg(\n",
    "    dataset_root='data/optic_disc_seg',\n",
    "    transforms=train_transforms,\n",
    "    mode='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证集预处理操作\n",
    "import paddleseg.transforms as T\n",
    "val_transforms = [\n",
    "    T.Resize(target_size=(512, 512)),\n",
    "    T.Normalize()\n",
    "]\n",
    "\n",
    "# 构建验证集\n",
    "from paddleseg.datasets import OpticDiscSeg\n",
    "val_dataset = OpticDiscSeg(\n",
    "    dataset_root='data/optic_disc_seg',\n",
    "    transforms=val_transforms,\n",
    "    mode='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建优化器\n",
    "\n",
    "Paddle框架提供了丰富的[学习率策略API和优化器API](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html)，本教程使用PolynomialDecay学习率策略，用法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "base_lr = 0.01\n",
    "lr = paddle.optimizer.lr.PolynomialDecay(base_lr, power=0.9, decay_steps=1000, end_lr=0)\n",
    "optimizer = paddle.optimizer.Momentum(lr, parameters=model.parameters(), momentum=0.9, weight_decay=4.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建损失函数\n",
    "\n",
    "PaddleSeg在paddleseg.models.losses子模块中提供了分割模型常用的损失函数，为了适应多路损失，损失函数应构建成包含'types'和'coef'的dict，如下所示。 \n",
    "\n",
    "其中losses['type']表示损失函数类型， losses['coef']为对应的系数。需注意len(losses['types'])应等于len(losses['coef'])。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleseg.models.losses import OhemCrossEntropyLoss\n",
    "losses = {}\n",
    "losses['types'] = [OhemCrossEntropyLoss(min_kept=200000)] * 3\n",
    "losses['coef'] = [1] * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 启动训练\n",
    "\n",
    "paddleseg.core提供了模型训练的API，指定参数后即可进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/norm.py:824: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:12:14 [INFO]\t[TRAIN] epoch: 1, iter: 10/1000, loss: 2.0496, lr: 0.009919, batch_cost: 0.3323, reader_cost: 0.01253, ips: 12.0356 samples/sec | ETA 00:05:29\n",
      "2024-02-13 20:12:14 [INFO]\t[TRAIN] epoch: 1, iter: 20/1000, loss: 0.6874, lr: 0.009829, batch_cost: 0.0625, reader_cost: 0.00019, ips: 63.9732 samples/sec | ETA 00:01:01\n",
      "2024-02-13 20:12:15 [INFO]\t[TRAIN] epoch: 1, iter: 30/1000, loss: 0.4588, lr: 0.009739, batch_cost: 0.0641, reader_cost: 0.00022, ips: 62.4071 samples/sec | ETA 00:01:02\n",
      "2024-02-13 20:12:16 [INFO]\t[TRAIN] epoch: 1, iter: 40/1000, loss: 0.3216, lr: 0.009648, batch_cost: 0.0630, reader_cost: 0.00019, ips: 63.4861 samples/sec | ETA 00:01:00\n",
      "2024-02-13 20:12:16 [INFO]\t[TRAIN] epoch: 1, iter: 50/1000, loss: 0.2227, lr: 0.009558, batch_cost: 0.0651, reader_cost: 0.00018, ips: 61.4117 samples/sec | ETA 00:01:01\n",
      "2024-02-13 20:12:17 [INFO]\t[TRAIN] epoch: 1, iter: 60/1000, loss: 0.2306, lr: 0.009467, batch_cost: 0.0652, reader_cost: 0.00019, ips: 61.3717 samples/sec | ETA 00:01:01\n",
      "2024-02-13 20:12:18 [INFO]\t[TRAIN] epoch: 2, iter: 70/1000, loss: 0.2201, lr: 0.009377, batch_cost: 0.0656, reader_cost: 0.00927, ips: 60.9528 samples/sec | ETA 00:01:01\n",
      "2024-02-13 20:12:18 [INFO]\t[TRAIN] epoch: 2, iter: 80/1000, loss: 0.1871, lr: 0.009286, batch_cost: 0.0683, reader_cost: 0.00036, ips: 58.5471 samples/sec | ETA 00:01:02\n",
      "2024-02-13 20:12:19 [INFO]\t[TRAIN] epoch: 2, iter: 90/1000, loss: 0.1490, lr: 0.009195, batch_cost: 0.0729, reader_cost: 0.00018, ips: 54.8487 samples/sec | ETA 00:01:06\n",
      "2024-02-13 20:12:20 [INFO]\t[TRAIN] epoch: 2, iter: 100/1000, loss: 0.1505, lr: 0.009104, batch_cost: 0.0806, reader_cost: 0.00017, ips: 49.6189 samples/sec | ETA 00:01:12\n",
      "2024-02-13 20:12:21 [INFO]\t[TRAIN] epoch: 2, iter: 110/1000, loss: 0.1911, lr: 0.009013, batch_cost: 0.0693, reader_cost: 0.00028, ips: 57.7268 samples/sec | ETA 00:01:01\n",
      "2024-02-13 20:12:21 [INFO]\t[TRAIN] epoch: 2, iter: 120/1000, loss: 0.2101, lr: 0.008922, batch_cost: 0.0734, reader_cost: 0.00030, ips: 54.4670 samples/sec | ETA 00:01:04\n",
      "2024-02-13 20:12:22 [INFO]\t[TRAIN] epoch: 2, iter: 130/1000, loss: 0.1830, lr: 0.008831, batch_cost: 0.0658, reader_cost: 0.00020, ips: 60.7451 samples/sec | ETA 00:00:57\n",
      "2024-02-13 20:12:23 [INFO]\t[TRAIN] epoch: 3, iter: 140/1000, loss: 0.1504, lr: 0.008740, batch_cost: 0.0700, reader_cost: 0.00839, ips: 57.1105 samples/sec | ETA 00:01:00\n",
      "2024-02-13 20:12:23 [INFO]\t[TRAIN] epoch: 3, iter: 150/1000, loss: 0.1459, lr: 0.008648, batch_cost: 0.0659, reader_cost: 0.00177, ips: 60.7335 samples/sec | ETA 00:00:55\n",
      "2024-02-13 20:12:24 [INFO]\t[TRAIN] epoch: 3, iter: 160/1000, loss: 0.1328, lr: 0.008557, batch_cost: 0.0644, reader_cost: 0.00019, ips: 62.1062 samples/sec | ETA 00:00:54\n",
      "2024-02-13 20:12:25 [INFO]\t[TRAIN] epoch: 3, iter: 170/1000, loss: 0.1151, lr: 0.008465, batch_cost: 0.0607, reader_cost: 0.00020, ips: 65.9137 samples/sec | ETA 00:00:50\n",
      "2024-02-13 20:12:25 [INFO]\t[TRAIN] epoch: 3, iter: 180/1000, loss: 0.1510, lr: 0.008374, batch_cost: 0.0640, reader_cost: 0.00023, ips: 62.5179 samples/sec | ETA 00:00:52\n",
      "2024-02-13 20:12:26 [INFO]\t[TRAIN] epoch: 3, iter: 190/1000, loss: 0.1096, lr: 0.008282, batch_cost: 0.0627, reader_cost: 0.00018, ips: 63.8105 samples/sec | ETA 00:00:50\n",
      "2024-02-13 20:12:27 [INFO]\t[TRAIN] epoch: 4, iter: 200/1000, loss: 0.1087, lr: 0.008190, batch_cost: 0.0693, reader_cost: 0.00805, ips: 57.6795 samples/sec | ETA 00:00:55\n",
      "2024-02-13 20:12:27 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 20ms/step - batch_cost: 0.0194 - reader cost: 4.3684e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:12:28 [INFO]\t[EVAL] #Images: 76 mIoU: 0.8875 Acc: 0.9956 Kappa: 0.8738 Dice: 0.9369\n",
      "2024-02-13 20:12:28 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9956 0.7794]\n",
      "2024-02-13 20:12:28 [INFO]\t[EVAL] Class Precision: \n",
      "[0.997  0.9176]\n",
      "2024-02-13 20:12:28 [INFO]\t[EVAL] Class Recall: \n",
      "[0.9986 0.8381]\n",
      "2024-02-13 20:12:28 [INFO]\t[EVAL] The model with the best validation mIoU (0.8875) was saved at iter 200.\n",
      "2024-02-13 20:12:29 [INFO]\t[TRAIN] epoch: 4, iter: 210/1000, loss: 0.0937, lr: 0.008098, batch_cost: 0.0709, reader_cost: 0.00025, ips: 56.4501 samples/sec | ETA 00:00:55\n",
      "2024-02-13 20:12:30 [INFO]\t[TRAIN] epoch: 4, iter: 220/1000, loss: 0.0964, lr: 0.008005, batch_cost: 0.0710, reader_cost: 0.00018, ips: 56.3217 samples/sec | ETA 00:00:55\n",
      "2024-02-13 20:12:31 [INFO]\t[TRAIN] epoch: 4, iter: 230/1000, loss: 0.1316, lr: 0.007913, batch_cost: 0.0750, reader_cost: 0.00019, ips: 53.3362 samples/sec | ETA 00:00:57\n",
      "2024-02-13 20:12:31 [INFO]\t[TRAIN] epoch: 4, iter: 240/1000, loss: 0.1088, lr: 0.007821, batch_cost: 0.0696, reader_cost: 0.00023, ips: 57.4785 samples/sec | ETA 00:00:52\n",
      "2024-02-13 20:12:32 [INFO]\t[TRAIN] epoch: 4, iter: 250/1000, loss: 0.1347, lr: 0.007728, batch_cost: 0.0688, reader_cost: 0.00020, ips: 58.1298 samples/sec | ETA 00:00:51\n",
      "2024-02-13 20:12:33 [INFO]\t[TRAIN] epoch: 4, iter: 260/1000, loss: 0.1054, lr: 0.007635, batch_cost: 0.0686, reader_cost: 0.00018, ips: 58.3507 samples/sec | ETA 00:00:50\n",
      "2024-02-13 20:12:33 [INFO]\t[TRAIN] epoch: 5, iter: 270/1000, loss: 0.1144, lr: 0.007543, batch_cost: 0.0700, reader_cost: 0.01232, ips: 57.1833 samples/sec | ETA 00:00:51\n",
      "2024-02-13 20:12:34 [INFO]\t[TRAIN] epoch: 5, iter: 280/1000, loss: 0.1133, lr: 0.007450, batch_cost: 0.0701, reader_cost: 0.00093, ips: 57.0414 samples/sec | ETA 00:00:50\n",
      "2024-02-13 20:12:35 [INFO]\t[TRAIN] epoch: 5, iter: 290/1000, loss: 0.1044, lr: 0.007357, batch_cost: 0.0635, reader_cost: 0.00022, ips: 62.9468 samples/sec | ETA 00:00:45\n",
      "2024-02-13 20:12:35 [INFO]\t[TRAIN] epoch: 5, iter: 300/1000, loss: 0.0865, lr: 0.007264, batch_cost: 0.0643, reader_cost: 0.00020, ips: 62.1658 samples/sec | ETA 00:00:45\n",
      "2024-02-13 20:12:36 [INFO]\t[TRAIN] epoch: 5, iter: 310/1000, loss: 0.0983, lr: 0.007170, batch_cost: 0.0664, reader_cost: 0.00027, ips: 60.2123 samples/sec | ETA 00:00:45\n",
      "2024-02-13 20:12:37 [INFO]\t[TRAIN] epoch: 5, iter: 320/1000, loss: 0.1300, lr: 0.007077, batch_cost: 0.0637, reader_cost: 0.00023, ips: 62.7876 samples/sec | ETA 00:00:43\n",
      "2024-02-13 20:12:37 [INFO]\t[TRAIN] epoch: 5, iter: 330/1000, loss: 0.1095, lr: 0.006983, batch_cost: 0.0658, reader_cost: 0.00019, ips: 60.8271 samples/sec | ETA 00:00:44\n",
      "2024-02-13 20:12:38 [INFO]\t[TRAIN] epoch: 6, iter: 340/1000, loss: 0.0823, lr: 0.006889, batch_cost: 0.0713, reader_cost: 0.01009, ips: 56.0689 samples/sec | ETA 00:00:47\n",
      "2024-02-13 20:12:39 [INFO]\t[TRAIN] epoch: 6, iter: 350/1000, loss: 0.0921, lr: 0.006796, batch_cost: 0.0613, reader_cost: 0.00020, ips: 65.2567 samples/sec | ETA 00:00:39\n",
      "2024-02-13 20:12:39 [INFO]\t[TRAIN] epoch: 6, iter: 360/1000, loss: 0.0899, lr: 0.006702, batch_cost: 0.0706, reader_cost: 0.00024, ips: 56.6475 samples/sec | ETA 00:00:45\n",
      "2024-02-13 20:12:40 [INFO]\t[TRAIN] epoch: 6, iter: 370/1000, loss: 0.0819, lr: 0.006607, batch_cost: 0.0701, reader_cost: 0.00020, ips: 57.0615 samples/sec | ETA 00:00:44\n",
      "2024-02-13 20:12:41 [INFO]\t[TRAIN] epoch: 6, iter: 380/1000, loss: 0.0810, lr: 0.006513, batch_cost: 0.0707, reader_cost: 0.00022, ips: 56.5722 samples/sec | ETA 00:00:43\n",
      "2024-02-13 20:12:42 [INFO]\t[TRAIN] epoch: 6, iter: 390/1000, loss: 0.0807, lr: 0.006419, batch_cost: 0.0704, reader_cost: 0.00019, ips: 56.8423 samples/sec | ETA 00:00:42\n",
      "2024-02-13 20:12:42 [INFO]\t[TRAIN] epoch: 7, iter: 400/1000, loss: 0.0916, lr: 0.006324, batch_cost: 0.0633, reader_cost: 0.01015, ips: 63.1757 samples/sec | ETA 00:00:37\n",
      "2024-02-13 20:12:42 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 20ms/step - batch_cost: 0.0199 - reader cost: 3.8186e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:12:44 [INFO]\t[EVAL] #Images: 76 mIoU: 0.9203 Acc: 0.9969 Kappa: 0.9137 Dice: 0.9569\n",
      "2024-02-13 20:12:44 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9969 0.8438]\n",
      "2024-02-13 20:12:44 [INFO]\t[EVAL] Class Precision: \n",
      "[0.9981 0.9329]\n",
      "2024-02-13 20:12:44 [INFO]\t[EVAL] Class Recall: \n",
      "[0.9988 0.8983]\n",
      "2024-02-13 20:12:44 [INFO]\t[EVAL] The model with the best validation mIoU (0.9203) was saved at iter 400.\n",
      "2024-02-13 20:12:45 [INFO]\t[TRAIN] epoch: 7, iter: 410/1000, loss: 0.0777, lr: 0.006229, batch_cost: 0.0746, reader_cost: 0.00020, ips: 53.6381 samples/sec | ETA 00:00:43\n",
      "2024-02-13 20:12:46 [INFO]\t[TRAIN] epoch: 7, iter: 420/1000, loss: 0.0770, lr: 0.006134, batch_cost: 0.0703, reader_cost: 0.00018, ips: 56.9115 samples/sec | ETA 00:00:40\n",
      "2024-02-13 20:12:46 [INFO]\t[TRAIN] epoch: 7, iter: 430/1000, loss: 0.0706, lr: 0.006039, batch_cost: 0.0710, reader_cost: 0.00019, ips: 56.3695 samples/sec | ETA 00:00:40\n",
      "2024-02-13 20:12:47 [INFO]\t[TRAIN] epoch: 7, iter: 440/1000, loss: 0.0793, lr: 0.005944, batch_cost: 0.0714, reader_cost: 0.00019, ips: 55.9895 samples/sec | ETA 00:00:40\n",
      "2024-02-13 20:12:48 [INFO]\t[TRAIN] epoch: 7, iter: 450/1000, loss: 0.0753, lr: 0.005848, batch_cost: 0.0694, reader_cost: 0.00019, ips: 57.6105 samples/sec | ETA 00:00:38\n",
      "2024-02-13 20:12:48 [INFO]\t[TRAIN] epoch: 7, iter: 460/1000, loss: 0.0880, lr: 0.005753, batch_cost: 0.0645, reader_cost: 0.00021, ips: 61.9907 samples/sec | ETA 00:00:34\n",
      "2024-02-13 20:12:49 [INFO]\t[TRAIN] epoch: 8, iter: 470/1000, loss: 0.0716, lr: 0.005657, batch_cost: 0.0643, reader_cost: 0.00580, ips: 62.1709 samples/sec | ETA 00:00:34\n",
      "2024-02-13 20:12:50 [INFO]\t[TRAIN] epoch: 8, iter: 480/1000, loss: 0.0777, lr: 0.005561, batch_cost: 0.0659, reader_cost: 0.00023, ips: 60.6680 samples/sec | ETA 00:00:34\n",
      "2024-02-13 20:12:50 [INFO]\t[TRAIN] epoch: 8, iter: 490/1000, loss: 0.0804, lr: 0.005465, batch_cost: 0.0625, reader_cost: 0.00024, ips: 63.9863 samples/sec | ETA 00:00:31\n",
      "2024-02-13 20:12:51 [INFO]\t[TRAIN] epoch: 8, iter: 500/1000, loss: 0.0703, lr: 0.005369, batch_cost: 0.0631, reader_cost: 0.00020, ips: 63.4324 samples/sec | ETA 00:00:31\n",
      "2024-02-13 20:12:52 [INFO]\t[TRAIN] epoch: 8, iter: 510/1000, loss: 0.0764, lr: 0.005272, batch_cost: 0.0605, reader_cost: 0.00023, ips: 66.1548 samples/sec | ETA 00:00:29\n",
      "2024-02-13 20:12:52 [INFO]\t[TRAIN] epoch: 8, iter: 520/1000, loss: 0.0763, lr: 0.005175, batch_cost: 0.0638, reader_cost: 0.00030, ips: 62.6659 samples/sec | ETA 00:00:30\n",
      "2024-02-13 20:12:53 [INFO]\t[TRAIN] epoch: 9, iter: 530/1000, loss: 0.0680, lr: 0.005078, batch_cost: 0.0642, reader_cost: 0.00707, ips: 62.3378 samples/sec | ETA 00:00:30\n",
      "2024-02-13 20:12:53 [INFO]\t[TRAIN] epoch: 9, iter: 540/1000, loss: 0.0644, lr: 0.004981, batch_cost: 0.0678, reader_cost: 0.00017, ips: 58.9956 samples/sec | ETA 00:00:31\n",
      "2024-02-13 20:12:54 [INFO]\t[TRAIN] epoch: 9, iter: 550/1000, loss: 0.0733, lr: 0.004884, batch_cost: 0.0679, reader_cost: 0.00029, ips: 58.9437 samples/sec | ETA 00:00:30\n",
      "2024-02-13 20:12:55 [INFO]\t[TRAIN] epoch: 9, iter: 560/1000, loss: 0.0666, lr: 0.004786, batch_cost: 0.0668, reader_cost: 0.00030, ips: 59.8515 samples/sec | ETA 00:00:29\n",
      "2024-02-13 20:12:56 [INFO]\t[TRAIN] epoch: 9, iter: 570/1000, loss: 0.0678, lr: 0.004688, batch_cost: 0.0673, reader_cost: 0.00023, ips: 59.4437 samples/sec | ETA 00:00:28\n",
      "2024-02-13 20:12:56 [INFO]\t[TRAIN] epoch: 9, iter: 580/1000, loss: 0.0747, lr: 0.004590, batch_cost: 0.0668, reader_cost: 0.00024, ips: 59.8827 samples/sec | ETA 00:00:28\n",
      "2024-02-13 20:12:57 [INFO]\t[TRAIN] epoch: 9, iter: 590/1000, loss: 0.0727, lr: 0.004492, batch_cost: 0.0669, reader_cost: 0.00021, ips: 59.7471 samples/sec | ETA 00:00:27\n",
      "2024-02-13 20:12:58 [INFO]\t[TRAIN] epoch: 10, iter: 600/1000, loss: 0.0664, lr: 0.004394, batch_cost: 0.0707, reader_cost: 0.00515, ips: 56.6041 samples/sec | ETA 00:00:28\n",
      "2024-02-13 20:12:58 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 19ms/step - batch_cost: 0.0186 - reader cost: 3.7472e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:12:59 [INFO]\t[EVAL] #Images: 76 mIoU: 0.9217 Acc: 0.9970 Kappa: 0.9153 Dice: 0.9577\n",
      "2024-02-13 20:12:59 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9969 0.8465]\n",
      "2024-02-13 20:12:59 [INFO]\t[EVAL] Class Precision: \n",
      "[0.9982 0.9325]\n",
      "2024-02-13 20:12:59 [INFO]\t[EVAL] Class Recall: \n",
      "[0.9988 0.9017]\n",
      "2024-02-13 20:12:59 [INFO]\t[EVAL] The model with the best validation mIoU (0.9217) was saved at iter 600.\n",
      "2024-02-13 20:13:00 [INFO]\t[TRAIN] epoch: 10, iter: 610/1000, loss: 0.0731, lr: 0.004295, batch_cost: 0.0692, reader_cost: 0.00020, ips: 57.8029 samples/sec | ETA 00:00:26\n",
      "2024-02-13 20:13:01 [INFO]\t[TRAIN] epoch: 10, iter: 620/1000, loss: 0.0704, lr: 0.004196, batch_cost: 0.0683, reader_cost: 0.00019, ips: 58.5688 samples/sec | ETA 00:00:25\n",
      "2024-02-13 20:13:01 [INFO]\t[TRAIN] epoch: 10, iter: 630/1000, loss: 0.0644, lr: 0.004097, batch_cost: 0.0688, reader_cost: 0.00018, ips: 58.1560 samples/sec | ETA 00:00:25\n",
      "2024-02-13 20:13:02 [INFO]\t[TRAIN] epoch: 10, iter: 640/1000, loss: 0.0645, lr: 0.003997, batch_cost: 0.0687, reader_cost: 0.00020, ips: 58.2502 samples/sec | ETA 00:00:24\n",
      "2024-02-13 20:13:03 [INFO]\t[TRAIN] epoch: 10, iter: 650/1000, loss: 0.0639, lr: 0.003897, batch_cost: 0.0704, reader_cost: 0.00190, ips: 56.8242 samples/sec | ETA 00:00:24\n",
      "2024-02-13 20:13:03 [INFO]\t[TRAIN] epoch: 10, iter: 660/1000, loss: 0.0719, lr: 0.003797, batch_cost: 0.0600, reader_cost: 0.00020, ips: 66.6213 samples/sec | ETA 00:00:20\n",
      "2024-02-13 20:13:04 [INFO]\t[TRAIN] epoch: 11, iter: 670/1000, loss: 0.0579, lr: 0.003697, batch_cost: 0.0689, reader_cost: 0.00619, ips: 58.0180 samples/sec | ETA 00:00:22\n",
      "2024-02-13 20:13:05 [INFO]\t[TRAIN] epoch: 11, iter: 680/1000, loss: 0.0651, lr: 0.003596, batch_cost: 0.0678, reader_cost: 0.00021, ips: 58.9553 samples/sec | ETA 00:00:21\n",
      "2024-02-13 20:13:05 [INFO]\t[TRAIN] epoch: 11, iter: 690/1000, loss: 0.0668, lr: 0.003495, batch_cost: 0.0649, reader_cost: 0.00020, ips: 61.6212 samples/sec | ETA 00:00:20\n",
      "2024-02-13 20:13:06 [INFO]\t[TRAIN] epoch: 11, iter: 700/1000, loss: 0.0603, lr: 0.003394, batch_cost: 0.0639, reader_cost: 0.00023, ips: 62.5842 samples/sec | ETA 00:00:19\n",
      "2024-02-13 20:13:07 [INFO]\t[TRAIN] epoch: 11, iter: 710/1000, loss: 0.0626, lr: 0.003292, batch_cost: 0.0612, reader_cost: 0.00019, ips: 65.3851 samples/sec | ETA 00:00:17\n",
      "2024-02-13 20:13:07 [INFO]\t[TRAIN] epoch: 11, iter: 720/1000, loss: 0.0564, lr: 0.003190, batch_cost: 0.0676, reader_cost: 0.00027, ips: 59.1475 samples/sec | ETA 00:00:18\n",
      "2024-02-13 20:13:08 [INFO]\t[TRAIN] epoch: 12, iter: 730/1000, loss: 0.0681, lr: 0.003088, batch_cost: 0.0704, reader_cost: 0.00947, ips: 56.7964 samples/sec | ETA 00:00:19\n",
      "2024-02-13 20:13:09 [INFO]\t[TRAIN] epoch: 12, iter: 740/1000, loss: 0.0672, lr: 0.002985, batch_cost: 0.0647, reader_cost: 0.00018, ips: 61.8222 samples/sec | ETA 00:00:16\n",
      "2024-02-13 20:13:09 [INFO]\t[TRAIN] epoch: 12, iter: 750/1000, loss: 0.0683, lr: 0.002882, batch_cost: 0.0632, reader_cost: 0.00228, ips: 63.3317 samples/sec | ETA 00:00:15\n",
      "2024-02-13 20:13:10 [INFO]\t[TRAIN] epoch: 12, iter: 760/1000, loss: 0.0621, lr: 0.002779, batch_cost: 0.0673, reader_cost: 0.00216, ips: 59.4712 samples/sec | ETA 00:00:16\n",
      "2024-02-13 20:13:11 [INFO]\t[TRAIN] epoch: 12, iter: 770/1000, loss: 0.0639, lr: 0.002675, batch_cost: 0.0705, reader_cost: 0.00573, ips: 56.7130 samples/sec | ETA 00:00:16\n",
      "2024-02-13 20:13:11 [INFO]\t[TRAIN] epoch: 12, iter: 780/1000, loss: 0.0657, lr: 0.002570, batch_cost: 0.0654, reader_cost: 0.00479, ips: 61.1177 samples/sec | ETA 00:00:14\n",
      "2024-02-13 20:13:12 [INFO]\t[TRAIN] epoch: 12, iter: 790/1000, loss: 0.0615, lr: 0.002465, batch_cost: 0.0655, reader_cost: 0.00253, ips: 61.0990 samples/sec | ETA 00:00:13\n",
      "2024-02-13 20:13:13 [INFO]\t[TRAIN] epoch: 13, iter: 800/1000, loss: 0.0594, lr: 0.002360, batch_cost: 0.0723, reader_cost: 0.01039, ips: 55.3280 samples/sec | ETA 00:00:14\n",
      "2024-02-13 20:13:13 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 20ms/step - batch_cost: 0.0192 - reader cost: 3.5140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:13:14 [INFO]\t[EVAL] #Images: 76 mIoU: 0.9202 Acc: 0.9970 Kappa: 0.9135 Dice: 0.9568\n",
      "2024-02-13 20:13:14 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9969 0.8435]\n",
      "2024-02-13 20:13:14 [INFO]\t[EVAL] Class Precision: \n",
      "[0.998  0.9409]\n",
      "2024-02-13 20:13:14 [INFO]\t[EVAL] Class Recall: \n",
      "[0.999  0.8907]\n",
      "2024-02-13 20:13:15 [INFO]\t[EVAL] The model with the best validation mIoU (0.9217) was saved at iter 600.\n",
      "2024-02-13 20:13:15 [INFO]\t[TRAIN] epoch: 13, iter: 810/1000, loss: 0.0622, lr: 0.002254, batch_cost: 0.0720, reader_cost: 0.00019, ips: 55.5784 samples/sec | ETA 00:00:13\n",
      "2024-02-13 20:13:16 [INFO]\t[TRAIN] epoch: 13, iter: 820/1000, loss: 0.0608, lr: 0.002147, batch_cost: 0.0689, reader_cost: 0.00018, ips: 58.0797 samples/sec | ETA 00:00:12\n",
      "2024-02-13 20:13:17 [INFO]\t[TRAIN] epoch: 13, iter: 830/1000, loss: 0.0605, lr: 0.002040, batch_cost: 0.0689, reader_cost: 0.00017, ips: 58.0778 samples/sec | ETA 00:00:11\n",
      "2024-02-13 20:13:17 [INFO]\t[TRAIN] epoch: 13, iter: 840/1000, loss: 0.0615, lr: 0.001933, batch_cost: 0.0694, reader_cost: 0.00018, ips: 57.6122 samples/sec | ETA 00:00:11\n",
      "2024-02-13 20:13:18 [INFO]\t[TRAIN] epoch: 13, iter: 850/1000, loss: 0.0565, lr: 0.001824, batch_cost: 0.0701, reader_cost: 0.00019, ips: 57.0280 samples/sec | ETA 00:00:10\n",
      "2024-02-13 20:13:19 [INFO]\t[TRAIN] epoch: 14, iter: 860/1000, loss: 0.0584, lr: 0.001715, batch_cost: 0.0658, reader_cost: 0.00532, ips: 60.7819 samples/sec | ETA 00:00:09\n",
      "2024-02-13 20:13:19 [INFO]\t[TRAIN] epoch: 14, iter: 870/1000, loss: 0.0564, lr: 0.001605, batch_cost: 0.0677, reader_cost: 0.00178, ips: 59.1269 samples/sec | ETA 00:00:08\n",
      "2024-02-13 20:13:20 [INFO]\t[TRAIN] epoch: 14, iter: 880/1000, loss: 0.0632, lr: 0.001495, batch_cost: 0.0647, reader_cost: 0.00023, ips: 61.8580 samples/sec | ETA 00:00:07\n",
      "2024-02-13 20:13:21 [INFO]\t[TRAIN] epoch: 14, iter: 890/1000, loss: 0.0579, lr: 0.001383, batch_cost: 0.0662, reader_cost: 0.00027, ips: 60.4560 samples/sec | ETA 00:00:07\n",
      "2024-02-13 20:13:21 [INFO]\t[TRAIN] epoch: 14, iter: 900/1000, loss: 0.0601, lr: 0.001270, batch_cost: 0.0685, reader_cost: 0.00020, ips: 58.4139 samples/sec | ETA 00:00:06\n",
      "2024-02-13 20:13:22 [INFO]\t[TRAIN] epoch: 14, iter: 910/1000, loss: 0.0559, lr: 0.001156, batch_cost: 0.0684, reader_cost: 0.00021, ips: 58.4656 samples/sec | ETA 00:00:06\n",
      "2024-02-13 20:13:23 [INFO]\t[TRAIN] epoch: 14, iter: 920/1000, loss: 0.0552, lr: 0.001041, batch_cost: 0.0684, reader_cost: 0.00017, ips: 58.5198 samples/sec | ETA 00:00:05\n",
      "2024-02-13 20:13:23 [INFO]\t[TRAIN] epoch: 15, iter: 930/1000, loss: 0.0628, lr: 0.000925, batch_cost: 0.0664, reader_cost: 0.00624, ips: 60.2549 samples/sec | ETA 00:00:04\n",
      "2024-02-13 20:13:24 [INFO]\t[TRAIN] epoch: 15, iter: 940/1000, loss: 0.0632, lr: 0.000807, batch_cost: 0.0671, reader_cost: 0.00021, ips: 59.5793 samples/sec | ETA 00:00:04\n",
      "2024-02-13 20:13:25 [INFO]\t[TRAIN] epoch: 15, iter: 950/1000, loss: 0.0533, lr: 0.000687, batch_cost: 0.0713, reader_cost: 0.00020, ips: 56.0650 samples/sec | ETA 00:00:03\n",
      "2024-02-13 20:13:25 [INFO]\t[TRAIN] epoch: 15, iter: 960/1000, loss: 0.0566, lr: 0.000564, batch_cost: 0.0680, reader_cost: 0.00032, ips: 58.8194 samples/sec | ETA 00:00:02\n",
      "2024-02-13 20:13:26 [INFO]\t[TRAIN] epoch: 15, iter: 970/1000, loss: 0.0554, lr: 0.000439, batch_cost: 0.0678, reader_cost: 0.00027, ips: 59.0004 samples/sec | ETA 00:00:02\n",
      "2024-02-13 20:13:27 [INFO]\t[TRAIN] epoch: 15, iter: 980/1000, loss: 0.0585, lr: 0.000309, batch_cost: 0.0624, reader_cost: 0.00032, ips: 64.0706 samples/sec | ETA 00:00:01\n",
      "2024-02-13 20:13:27 [INFO]\t[TRAIN] epoch: 15, iter: 990/1000, loss: 0.0613, lr: 0.000173, batch_cost: 0.0589, reader_cost: 0.00021, ips: 67.9203 samples/sec | ETA 00:00:00\n",
      "2024-02-13 20:13:28 [INFO]\t[TRAIN] epoch: 16, iter: 1000/1000, loss: 0.0567, lr: 0.000020, batch_cost: 0.0749, reader_cost: 0.00728, ips: 53.3809 samples/sec | ETA 00:00:00\n",
      "2024-02-13 20:13:28 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 19ms/step - batch_cost: 0.0191 - reader cost: 3.6953e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:13:30 [INFO]\t[EVAL] #Images: 76 mIoU: 0.9200 Acc: 0.9970 Kappa: 0.9133 Dice: 0.9567\n",
      "2024-02-13 20:13:30 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9969 0.8431]\n",
      "2024-02-13 20:13:30 [INFO]\t[EVAL] Class Precision: \n",
      "[0.9978 0.948 ]\n",
      "2024-02-13 20:13:30 [INFO]\t[EVAL] Class Recall: \n",
      "[0.9991 0.8839]\n",
      "2024-02-13 20:13:30 [INFO]\t[EVAL] The model with the best validation mIoU (0.9217) was saved at iter 600.\n",
      "<class 'paddle.nn.layer.conv.Conv2D'>'s flops has been counted\n",
      "<class 'paddle.nn.layer.norm.BatchNorm2D'>'s flops has been counted\n",
      "<class 'paddle.nn.layer.activation.ReLU'>'s flops has been counted\n",
      "<class 'paddle.nn.layer.pooling.AvgPool2D'>'s flops has been counted\n",
      "<class 'paddle.nn.layer.pooling.AdaptiveAvgPool2D'>'s flops has been counted\n",
      "Total Flops: 6339220352     Total Params: 8214802\n"
     ]
    }
   ],
   "source": [
    "from paddleseg.core import train\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    optimizer=optimizer,\n",
    "    save_dir='output',\n",
    "    iters=1000,\n",
    "    batch_size=4,\n",
    "    save_interval=200,\n",
    "    log_iters=10,\n",
    "    num_workers=0,\n",
    "    losses=losses,\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恢复训练\n",
    "\n",
    "如果需要恢复训练，只需指定参数resume_model即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleseg.core import train\n",
    "from paddleseg.models import PPLiteSeg\n",
    "from paddleseg.models.backbones import STDC1\n",
    "\n",
    "model = PPLiteSeg(\n",
    "    num_classes=2, # 背景+前景类别数\n",
    "    backbone=STDC1()\n",
    ")\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    optimizer=optimizer,\n",
    "    save_dir='output',\n",
    "    iters=1000,\n",
    "    batch_size=4,\n",
    "    save_interval=200,\n",
    "    log_iters=10,\n",
    "    num_workers=0,\n",
    "    losses=losses,\n",
    "    resume_model='output/iter_200',\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 模型评估与预测\n",
    "\n",
    "PaddleSeg在训练时是以[paddle基础API保存模型](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/beginner/model_save_load_cn.html)，因此在加载模型参数时也对应使用paddle基础API。\n",
    "\n",
    "### 模型评估\n",
    "\n",
    "paddleseg.core提供了模型评估的API，指定参数后即可进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained params of model successfully\n",
      "2024-02-13 20:14:00 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv._conv.total_ops. seg_heads.1.conv._conv.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv._conv.total_params. seg_heads.1.conv._conv.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv._batch_norm.total_ops. seg_heads.1.conv._batch_norm.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv._batch_norm.total_params. seg_heads.1.conv._batch_norm.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv._relu.act_func.total_ops. seg_heads.1.conv._relu.act_func.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv._relu.act_func.total_params. seg_heads.1.conv._relu.act_func.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv_out.total_ops. seg_heads.1.conv_out.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.1.conv_out.total_params. seg_heads.1.conv_out.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv._conv.total_ops. seg_heads.2.conv._conv.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv._conv.total_params. seg_heads.2.conv._conv.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv._batch_norm.total_ops. seg_heads.2.conv._batch_norm.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv._batch_norm.total_params. seg_heads.2.conv._batch_norm.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv._relu.act_func.total_ops. seg_heads.2.conv._relu.act_func.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv._relu.act_func.total_params. seg_heads.2.conv._relu.act_func.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv_out.total_ops. seg_heads.2.conv_out.total_ops is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "/root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for seg_heads.2.conv_out.total_params. seg_heads.2.conv_out.total_params is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "76/76 [==============================] - 1s 19ms/step - batch_cost: 0.0187 - reader cost: 4.6280e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:14:01 [INFO]\t[EVAL] #Images: 76 mIoU: 0.9217 Acc: 0.9970 Kappa: 0.9153 Dice: 0.9577\n",
      "2024-02-13 20:14:01 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9969 0.8465]\n",
      "2024-02-13 20:14:01 [INFO]\t[EVAL] Class Precision: \n",
      "[0.9982 0.9325]\n",
      "2024-02-13 20:14:01 [INFO]\t[EVAL] Class Recall: \n",
      "[0.9988 0.9017]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9217038174435206,\n",
       " 0.9969968844186231,\n",
       " array([0.99694633, 0.84646131]),\n",
       " array([0.99816234, 0.93251858]),\n",
       " 0.9153183253929513)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始评估\n",
    "import paddle\n",
    "model_path = 'output/best_model/model.pdparams'\n",
    "if model_path:\n",
    "    para_state_dict = paddle.load(model_path)\n",
    "    model.set_dict(para_state_dict)\n",
    "    print('Loaded trained params of model successfully')\n",
    "else: \n",
    "    raise ValueError('The model_path is wrong: {}'.format(model_path))\n",
    "\n",
    "from paddleseg.core import evaluate\n",
    "evaluate(\n",
    "    model,\n",
    "    val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:14:19 [INFO]\tStart evaluating (total_samples: 76, total_iters: 76)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 7s 86ms/step - batch_cost: 0.0850 - reader cost: 4.2746e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:14:26 [INFO]\t[EVAL] #Images: 76 mIoU: 0.9258 Acc: 0.9972 Kappa: 0.9201 Dice: 0.9600\n",
      "2024-02-13 20:14:26 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9971 0.8544]\n",
      "2024-02-13 20:14:26 [INFO]\t[EVAL] Class Precision: \n",
      "[0.9981 0.9438]\n",
      "2024-02-13 20:14:26 [INFO]\t[EVAL] Class Recall: \n",
      "[0.999  0.9003]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9257831669139771,\n",
       " 0.9971838110392872,\n",
       " array([0.99713648, 0.85442986]),\n",
       " array([0.99813583, 0.94377945]),\n",
       " 0.9200684014326543)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型多尺度+翻转评估\n",
    "evaluate(\n",
    "        model,\n",
    "        val_dataset,\n",
    "        aug_eval=True,\n",
    "        scales=[0.75, 1.0, 1.25],\n",
    "        flip_horizontal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型预测\n",
    "\n",
    "paddleseg.core提供了模型预测的API，在预测时需传入待预测的图像列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建待预测的图像列表\n",
    "import os\n",
    "def get_image_list(image_path):\n",
    "    \"\"\"Get image list\"\"\"\n",
    "    valid_suffix = [\n",
    "        '.JPEG', '.jpeg', '.JPG', '.jpg', '.BMP', '.bmp', '.PNG', '.png'\n",
    "    ]\n",
    "    image_list = []\n",
    "    image_dir = None\n",
    "    if os.path.isfile(image_path):\n",
    "        if os.path.splitext(image_path)[-1] in valid_suffix:\n",
    "            image_list.append(image_path)\n",
    "    elif os.path.isdir(image_path):\n",
    "        image_dir = image_path\n",
    "        for root, dirs, files in os.walk(image_path):\n",
    "            for f in files:\n",
    "                if os.path.splitext(f)[-1] in valid_suffix:\n",
    "                    image_list.append(os.path.join(root, f))\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            '`--image_path` is not found. it should be an image file or a directory including images'\n",
    "        )\n",
    "\n",
    "    if len(image_list) == 0:\n",
    "        raise RuntimeError('There are not image file in `--image_path`')\n",
    "\n",
    "    return image_list, image_dir\n",
    "image_path = 'data/optic_disc_seg/JPEGImages/N0010.jpg' # 也可以输入一个包含图像的目录\n",
    "image_list, image_dir = get_image_list('data/optic_disc_seg/JPEGImages/N0010.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定predict函数所需参数后即可进行预测，预测后的结果图保存在save_dir指定的目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:16:13 [INFO]\tLoading pretrained model from output/best_model/model.pdparams\n",
      "2024-02-13 20:16:13 [INFO]\tThere are 250/250 variables loaded into PPLiteSeg.\n",
      "2024-02-13 20:16:13 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 20:16:13 [INFO]\tPredicted images are saved in output/results/added_prediction and output/results/pseudo_color_prediction .\n"
     ]
    }
   ],
   "source": [
    "# 开始预测\n",
    "from paddleseg.core import predict\n",
    "import paddleseg.transforms as T\n",
    "from paddleseg.models import PPLiteSeg\n",
    "from paddleseg.models.backbones import STDC1\n",
    "\n",
    "model = PPLiteSeg(\n",
    "    num_classes=2, # 背景+前景类别数\n",
    "    backbone=STDC1()\n",
    ")\n",
    "pred_transforms = T.Compose([\n",
    "    T.Resize(target_size=(512, 512)),\n",
    "    T.Normalize()\n",
    "])\n",
    "\n",
    "predict(\n",
    "        model,\n",
    "        model_path='output/best_model/model.pdparams',\n",
    "        transforms=pred_transforms,\n",
    "        image_list=image_list,\n",
    "        image_dir=image_dir,\n",
    "        save_dir='output/results'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测结果可视化\n",
    "\n",
    "预测的伪彩色图如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f373b993061843988434d80c82715597a491477c655a40f7a426d18dac9472aa)\n",
    "\n",
    "\n",
    "叠加结果图如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a4db253645d34ce09f8ae45e08c59bfae69d90e1f4c34f978333031484facaa5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概述\n",
    "\n",
    "上一节我们研究了资源部署优化的方法，通过使用单GPU和分布式部署，提升模型训练的效率。本节我们依旧横向展开\"横纵式\"，如 **图1** 所示，探讨在手写数字识别任务中，为了保证模型的真实效果，在模型训练部分，对模型进行一些调试和优化的方法。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/0f94e16e03f34223903319eb50c8c09687d203f0e718491bbc7c4fc1b2a88585\" width=\"1000\" hegiht=\"\" ></center>\n",
    "<center>图1：“横纵式”教学法 — 训练过程</center>\n",
    "<br></br>\n",
    "\n",
    "训练过程优化思路主要有如下五个关键环节：\n",
    "\n",
    "**1. 计算分类准确率，观测模型训练效果。**\n",
    "\n",
    "交叉熵损失函数只能作为优化目标，无法直接准确衡量模型的训练效果。准确率可以直接衡量训练效果，但由于其离散性质，不适合做为损失函数优化神经网络。\n",
    "    \n",
    "**2. 检查模型训练过程，识别潜在问题。**\n",
    "\n",
    "如果模型的损失或者评估指标表现异常，通常需要打印模型每一层的输入和输出来定位问题，分析每一层的内容来获取错误的原因。\n",
    "    \n",
    "**3. 加入校验或测试，更好评价模型效果。**\n",
    "\n",
    "理想的模型训练结果是在训练集和验证集上均有较高的准确率，如果训练集的准确率低于验证集，说明网络训练程度不够；如果训练集的准确率高于验证集，可能是发生了过拟合现象。通过在优化目标中加入正则化项的办法，解决过拟合的问题。\n",
    "    \n",
    "**4. 加入正则化项，避免模型过拟合。**\n",
    "\n",
    "飞桨框架支持为整体参数加入正则化项，这是通常的做法。此外，飞桨框架也支持为某一层或某一部分的网络单独加入正则化项，以达到精细调整参数训练的效果。\n",
    "\n",
    "**5. 可视化分析。**\n",
    "\n",
    "用户不仅可以通过打印或使用matplotlib库作图，飞桨还提供了更专业的可视化分析工具VisualDL，提供便捷的可视化分析方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算模型的分类准确率\n",
    "\n",
    "准确率是一个直观衡量分类模型效果的指标，由于这个指标是离散的，因此不适合作为损失来优化。通常情况下，交叉熵损失越小的模型，分类的准确率也越高。基于分类准确率，我们可以公平地比较两种损失函数的优劣，例如在【手写数字识别】之损失函数章节中均方误差和交叉熵的比较。\n",
    "\n",
    "使用飞桨提供的计算分类准确率API，可以直接计算准确率。\n",
    "\n",
    "> *class* paddle.metric.Accuracy\n",
    "\n",
    "该API的输入参数input为预测的分类结果predict，输入参数label为数据真实的label。飞桨还提供了更多衡量模型效果的计算指标，详细可以查看paddle.meric包下面的API。\n",
    "\n",
    "在下述代码中，我们在模型前向计算过程forward函数中计算分类准确率，并在训练时打印每个批次样本的分类准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载相关库\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "\n",
    "# 定义数据集读取器\n",
    "def load_data(mode='train'):\n",
    "\n",
    "    # 读取数据文件\n",
    "    datafile = './work/mnist.json.gz'\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\n",
    "    data = json.load(gzip.open(datafile))\n",
    "    # 读取数据集中的训练集，验证集和测试集\n",
    "    train_set, val_set, eval_set = data\n",
    "\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "    # 根据输入mode参数决定使用训练集，验证集还是测试\n",
    "    if mode == 'train':\n",
    "        imgs = train_set[0]\n",
    "        labels = train_set[1]\n",
    "    elif mode == 'valid':\n",
    "        imgs = val_set[0]\n",
    "        labels = val_set[1]\n",
    "    elif mode == 'eval':\n",
    "        imgs = eval_set[0]\n",
    "        labels = eval_set[1]\n",
    "    # 获得所有图像的数量\n",
    "    imgs_length = len(imgs)\n",
    "    # 验证图像数量和标签数量是否一致\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\n",
    "                  len(imgs), len(labels))\n",
    "\n",
    "    index_list = list(range(imgs_length))\n",
    "\n",
    "    # 读入数据时用到的batchsize\n",
    "    BATCHSIZE = 100\n",
    "\n",
    "    # 定义数据生成器\n",
    "    def data_generator():\n",
    "        # 训练模式下，打乱训练数据\n",
    "        if mode == 'train':\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        # 按照索引读取数据\n",
    "        for i in index_list:\n",
    "            # 读取图像和标签，转换其尺寸和类型\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('int64')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            # 如果当前数据缓存达到了batch size，就返回一个批次数据\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                # 清空数据缓存列表\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from ./work/mnist.json.gz ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0111 17:28:37.697688 319250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.3, Runtime API Version: 12.0\n",
      "W0111 17:28:37.698868 319250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: 2.5176801681518555, acc is 0.2199999988079071\n",
      "epoch: 0, batch: 200, loss is: 0.22583630681037903, acc is 0.9200000166893005\n",
      "epoch: 0, batch: 400, loss is: 0.06658145040273666, acc is 0.9800000190734863\n",
      "epoch: 1, batch: 0, loss is: 0.15673115849494934, acc is 0.9599999785423279\n",
      "epoch: 1, batch: 200, loss is: 0.1565537303686142, acc is 0.9800000190734863\n",
      "epoch: 1, batch: 400, loss is: 0.15611395239830017, acc is 0.9599999785423279\n",
      "epoch: 2, batch: 0, loss is: 0.023068638518452644, acc is 0.9900000095367432\n",
      "epoch: 2, batch: 200, loss is: 0.0956333577632904, acc is 0.9700000286102295\n",
      "epoch: 2, batch: 400, loss is: 0.05429626628756523, acc is 0.9700000286102295\n",
      "epoch: 3, batch: 0, loss is: 0.11658403277397156, acc is 0.9700000286102295\n",
      "epoch: 3, batch: 200, loss is: 0.12490040063858032, acc is 0.9800000190734863\n",
      "epoch: 3, batch: 400, loss is: 0.0313369445502758, acc is 0.9900000095367432\n",
      "epoch: 4, batch: 0, loss is: 0.07334521412849426, acc is 0.9800000190734863\n",
      "epoch: 4, batch: 200, loss is: 0.03699391707777977, acc is 0.9900000095367432\n",
      "epoch: 4, batch: 400, loss is: 0.08820755779743195, acc is 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# 定义模型结构\n",
    "import paddle.nn.functional as F\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "\n",
    "# 多层卷积神经网络实现\n",
    "class MNIST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "         \n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义一层全连接层，输出维度是10\n",
    "        self.fc = Linear(in_features=980, out_features=10)\n",
    "         \n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "    # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "    def forward(self, inputs, label):\n",
    "        x = self.conv1(inputs)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = paddle.reshape(x, [x.shape[0], 980])\n",
    "        x = self.fc(x)\n",
    "        if label is not None:\n",
    "           acc = paddle.metric.accuracy(input=x, label=label)\n",
    "           return x, acc\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "#调用加载数据的函数\n",
    "train_loader = load_data('train')\n",
    "\n",
    "#在使用GPU机器时，可以将use_gpu变量设置成True\n",
    "use_gpu = True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\n",
    "\n",
    "#仅优化算法的设置有所差别\n",
    "def train(model):\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    \n",
    "    # 四种优化算法的设置方案，可以逐一尝试效果\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Momentum(learning_rate=0.01, momentum=0.9, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程\n",
    "            predicts, acc = model(images, labels)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "                \n",
    "            #后向传播，更新参数，消除梯度的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "#创建模型    \n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查模型训练过程，识别潜在训练问题\n",
    "\n",
    "使用飞桨动态图编程可以方便的查看和调试训练的执行过程。在网络定义的Forward函数中，可以打印每一层输入输出的尺寸，以及每层网络的参数。通过查看这些信息，不仅可以更好地理解训练的执行过程，还可以发现潜在问题，或者启发继续优化的思路。\n",
    "\n",
    "在下述程序中，使用``check_shape``变量控制是否打印“尺寸”，验证网络结构是否正确。使用``check_content``变量控制是否打印“内容值”，验证数据分布是否合理。假如在训练中发现中间层的部分输出持续为0，说明该部分的网络结构设计存在问题，没有充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## print network layer's superparams ##############\n",
      "conv1-- kernel_size:[20, 1, 5, 5], padding:2, stride:[1, 1]\n",
      "conv2-- kernel_size:[20, 20, 5, 5], padding:2, stride:[1, 1]\n",
      "fc-- weight_size:[980, 10], bias_size_[10]\n",
      "\n",
      "########## print shape of features of every layer ###############\n",
      "inputs_shape: [100, 1, 28, 28]\n",
      "outputs1_shape: [100, 20, 28, 28]\n",
      "outputs2_shape: [100, 20, 28, 28]\n",
      "outputs3_shape: [100, 20, 14, 14]\n",
      "outputs4_shape: [100, 20, 14, 14]\n",
      "outputs5_shape: [100, 20, 14, 14]\n",
      "outputs6_shape: [100, 980]\n",
      "outputs7_shape: [100, 10]\n",
      "epoch: 0, batch: 0, loss is: 4.6394805908203125, acc is 0.07999999821186066\n",
      "epoch: 0, batch: 200, loss is: 0.3219357430934906, acc is 0.9200000166893005\n",
      "epoch: 0, batch: 400, loss is: 0.3067660927772522, acc is 0.8799999952316284\n",
      "\n",
      "########## print convolution layer's kernel ###############\n",
      "conv1 params -- kernel weights: Tensor(shape=[5, 5], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[ 0.36773777, -0.08795562, -0.63577360, -0.19974339,  0.08527818],\n",
      "        [-0.10733707,  0.25129020, -0.15388496, -0.18681283,  0.49541724],\n",
      "        [ 0.19823900, -0.14942892,  0.00249939, -0.09486459,  0.05470544],\n",
      "        [ 0.07535495, -0.06493863,  0.61361802,  0.13383210, -0.00331119],\n",
      "        [-0.01049814,  0.24362880,  0.09233665, -0.26500002,  0.01624365]])\n",
      "conv2 params -- kernel weights: Tensor(shape=[5, 5], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[-0.01081778,  0.00335373,  0.05348165,  0.07897394,  0.05262304],\n",
      "        [-0.07035918, -0.00877686,  0.02269374, -0.03694367,  0.01552693],\n",
      "        [ 0.03112385, -0.00422856, -0.03841285, -0.09305786, -0.04548384],\n",
      "        [-0.01808186, -0.07247280,  0.06195984, -0.06135036, -0.01324027],\n",
      "        [ 0.00936094,  0.02778168,  0.05905245,  0.05571734,  0.02756141]])\n",
      "\n",
      "The 4th channel of conv1 layer:  Tensor(shape=[28, 28], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[-1.01718962, -1.03929460, -1.40114605, -1.40114605, -1.40114605,\n",
      "         -1.40114605, -1.40114605, -1.40114605, -1.40114605, -1.40114605,\n",
      "         -1.40114605, -1.40114605, -1.40114605, -1.40114605, -1.40114605,\n",
      "         -1.40114605, -1.40114605, -1.40114605, -1.40114605, -1.40114605,\n",
      "         -1.40114605, -1.40114605, -1.40114605, -1.40114605, -1.40114605,\n",
      "         -1.40114605, -1.46565402, -0.76646990],\n",
      "        [-1.57922304, -1.61747682, -1.66066611, -1.66066611, -1.66066611,\n",
      "         -1.66066611, -1.66066611, -1.66066611, -1.66066611, -1.66066611,\n",
      "         -1.66066611, -1.66066611, -1.66066611, -1.66066611, -1.66066611,\n",
      "         -1.66066611, -1.66066611, -1.66066611, -1.66066611, -1.66066611,\n",
      "         -1.66066611, -1.66066611, -1.66066611, -1.66066611, -1.66066611,\n",
      "         -1.66066611, -1.45646656, -0.59643382],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.74127823, -0.63359702, -0.37735483, -0.10631506,\n",
      "         -0.04426020, -0.21283612, -0.67118829, -0.72841680, -0.49615932,\n",
      "         -0.13991635, -0.66920042, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.62923139, -0.20866638,  0.09887305, -0.32205057,\n",
      "         -0.19761181,  0.80088556,  1.11209691,  1.01770937,  0.14413273,\n",
      "         -0.51746887, -0.54975104, -0.28616190, -0.54828906, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.75676262,\n",
      "         -0.63581032, -0.25117517, -0.08650789, -0.19235255,  0.37809297,\n",
      "          1.50729501,  1.76881206,  2.21592784,  1.25619102,  1.21278501,\n",
      "          0.64961892, -0.23389991, -0.69211912, -0.32111034, -0.24723925,\n",
      "         -0.74174714, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.70615768,\n",
      "         -0.38642782, -0.16264865,  0.27808937,  0.79377079,  2.05310798,\n",
      "          2.44201255,  2.57075286,  1.19884121,  0.39575487,  0.28725043,\n",
      "          0.67549968,  0.92766941, -0.56238353, -0.86692715,  0.14936431,\n",
      "         -0.73334861, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.72800589, -0.45165375,\n",
      "         -0.16134265,  0.19016980,  0.94821537,  2.06124663,  2.66448092,\n",
      "          1.67588818, -0.34016660, -1.34281564, -1.39019346, -0.97272539,\n",
      "         -0.66575241, -0.11868747,  0.14986886, -0.45292178, -0.83735311,\n",
      "         -0.76251340, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.58272898, -0.21070626,\n",
      "         -0.00836442,  1.17680120,  2.02526379,  2.76150417,  0.32174203,\n",
      "         -0.83117700, -2.67520452, -2.48450017, -2.02936339, -1.98568738,\n",
      "         -1.39105964, -0.80151296, -1.25324380, -1.06595588, -1.35871446,\n",
      "         -0.77555418, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.69814306, -0.42495576, -0.22251929,\n",
      "          1.29422307,  1.65177858,  2.94860864,  0.57749379, -1.46186960,\n",
      "         -2.57495332, -2.93150544, -2.16559100, -1.77883613, -1.51797116,\n",
      "         -1.41285133, -1.79276311, -1.97108996, -2.00703692, -1.67121422,\n",
      "         -0.78273308, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.66529417, -0.53747904,  0.81855357,\n",
      "          1.81583166,  2.36456633,  1.69730699, -0.98752809, -1.96131098,\n",
      "         -2.42850137, -1.56966770, -0.87203014, -0.75755799, -0.75217617,\n",
      "         -0.78177869, -1.19390738, -1.67488444, -1.66482055, -1.36371851,\n",
      "         -0.77275932, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75233853, -0.61232638,  0.10541853,  1.53131282,\n",
      "          1.68130362,  2.51748800,  0.64254320, -1.73647964, -1.75256622,\n",
      "         -1.68324769, -0.86706662, -0.75786865, -0.75786865, -0.75782979,\n",
      "         -0.75785172, -0.76392603, -0.79063785, -0.78806031, -0.78764999,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.70945942, -0.44154233,  0.49941421,  1.80523407,\n",
      "          1.54942513,  2.29620409,  0.38726443, -1.66573763, -2.05834436,\n",
      "         -1.30905414, -0.48341966, -0.65710926, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.66178811, -0.39533135,  1.12226260,  1.77785265,\n",
      "          2.15532780,  1.42151666, -0.19730020, -0.54411751, -0.77255148,\n",
      "         -0.47862333, -0.26602039, -0.69581664, -0.39661774, -0.29829121,\n",
      "         -0.60068405, -0.75786865, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.72086751, -0.12762606,  1.62480724,  2.06534863,\n",
      "          1.54649591,  0.66358024, -0.14884549,  0.21258248, -0.87147117,\n",
      "          0.20068063,  1.53205919,  0.49776185, -0.06828496, -0.72903907,\n",
      "         -0.36369374, -0.23081066, -0.74577761, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.71571684,  0.27255970,  1.69978321,  1.70477676,\n",
      "          1.13094568, -0.01785297, -0.61200571,  0.27465048, -0.12772144,\n",
      "         -0.01304182,  0.98248369,  1.29116714,  0.97247642, -0.40251639,\n",
      "         -0.68723786, -0.28092539, -0.23769675, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.62205184,  0.27366954,  1.65392864,  1.65873992,\n",
      "          0.63720655, -0.27773947,  0.23141898, -0.75957918, -0.78302753,\n",
      "         -0.20882480, -0.46755248,  0.10380062,  0.69631082,  0.71023542,\n",
      "         -0.48525918, -0.81500781, -0.04632701, -0.58859289, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.69180691,  0.05022690,  1.23824561,  1.93330979,\n",
      "          0.52108377, -1.63744032, -1.51586497, -1.96067154, -1.98123085,\n",
      "         -2.10356355, -2.26134348, -1.12033010, -0.61724877,  0.66916305,\n",
      "          0.11728095, -1.24359846, -0.64937842,  0.01951115, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.64054334, -0.09106021,  0.80552202,  1.70203686,\n",
      "          0.19022587, -2.40601540, -2.72018623, -1.72987020, -1.97170961,\n",
      "         -1.98535931, -1.74789989, -1.32489431, -0.79717267, -0.11065342,\n",
      "         -0.26430294, -1.14804912, -0.91565549,  0.12537159, -0.73368645,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.60299253, -0.38632929,  0.29154640,  0.29148710,\n",
      "          0.42374575, -1.01462376, -2.65596843, -1.43072677,  0.03615500,\n",
      "         -0.82115018, -0.78888667, -0.48358917, -0.36247078,  0.08299734,\n",
      "          0.08910100, -1.02446783, -1.02169299, -0.30430767, -0.55584311,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.74589682, -0.45385203, -0.22835587, -0.07342468,\n",
      "         -0.07692157, -0.22703363, -0.31835765, -0.96697623, -0.50597537,\n",
      "         -0.40946376, -0.43875888, -0.28618538,  0.14795247,  0.89297515,\n",
      "          0.48901603, -0.61879849, -1.05829787, -0.57152951, -0.76137269,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75777161, -0.60780954, -0.28584746, -0.41566092,\n",
      "         -0.57794833, -0.44542760, -0.35983834,  0.21621028,  0.35910901,\n",
      "          0.28930643,  0.15038650,  0.19284895,  0.46539995,  1.42046309,\n",
      "          1.19377863,  0.18040033, -1.52230513, -1.08264136, -0.83719993,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75650966, -0.60592425, -0.48826039,\n",
      "         -0.42799523, -0.79519141, -0.68546116, -0.59678710,  0.15952910,\n",
      "          0.88830888,  0.73241329,  0.40472037,  0.97842836,  1.87050307,\n",
      "          1.61268198,  0.25381324, -1.26338565, -2.09725285, -0.89723682,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75221407, -0.48755467,\n",
      "         -0.34072611, -0.47787166, -0.73928273, -0.74489653, -0.63531089,\n",
      "         -0.22448312,  0.06218465,  0.75826347,  1.74242294,  2.05229735,\n",
      "          1.23870027, -1.28605759, -2.25669742, -2.34021068, -0.88195729,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75782979, -0.74924362,\n",
      "         -0.62325168, -0.68969667, -0.93417299, -1.28877914, -1.34334075,\n",
      "         -0.85853803, -0.08258434,  0.55948496,  0.92954075,  0.40114126,\n",
      "         -1.17152917, -2.41190195, -2.56432509, -1.94013512, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.75781047,\n",
      "         -0.75685322, -0.76953351, -0.92351544, -1.14302754, -1.38841188,\n",
      "         -1.45872653, -1.43414545, -1.50301850, -1.84646118, -2.46029949,\n",
      "         -2.86492944, -2.95356965, -2.20106244, -1.40092647, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-1.26319122, -1.03234553, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75786865, -0.75786865, -0.75786865,\n",
      "         -0.75786865, -0.75786865, -0.75771344, -0.75747120, -0.78084779,\n",
      "         -0.94189250, -1.31408846, -1.85247171, -2.28504205, -2.44046640,\n",
      "         -2.19830394, -1.69838941, -1.18348217, -0.84721255, -0.75786865,\n",
      "         -0.75786865, -0.55118412,  0.29501867],\n",
      "        [-0.75459027, -1.07894051, -0.28857544, -0.28857544, -0.28857544,\n",
      "         -0.28857544, -0.28857544, -0.28857544, -0.28857544, -0.28857544,\n",
      "         -0.28857544, -0.28857544, -0.28857544, -0.28857544, -0.28857544,\n",
      "         -0.28857544, -0.28857544, -0.28857544, -0.28857544, -0.28857544,\n",
      "         -0.28857544, -0.28857544, -0.28857544, -0.28857544, -0.28857544,\n",
      "         -0.28857544, -0.22346266,  0.28902370],\n",
      "        [-0.59818572, -0.68902314,  0.11215362,  0.11215362,  0.11215362,\n",
      "          0.11215362,  0.11215362,  0.11215362,  0.11215362,  0.11215362,\n",
      "          0.11215362,  0.11215362,  0.11215362,  0.11215362,  0.11215362,\n",
      "          0.11215362,  0.11215362,  0.11215362,  0.11215362,  0.11215362,\n",
      "          0.11215362,  0.11215362,  0.11215362,  0.11215362,  0.11215362,\n",
      "          0.11215362,  0.21213536,  0.91667730]])\n",
      "The 5th channel of conv2 layer:  Tensor(shape=[14, 14], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[-1.50698256, -1.11985862, -0.84704828, -0.51542902, -0.80736035,\n",
      "         -0.95091617, -0.92737138, -0.63239032, -0.95315224, -0.78735089,\n",
      "         -1.52901256, -1.44509482, -1.03024161,  0.59181255],\n",
      "        [-1.96364832, -1.56697893, -1.58710575, -1.91653192, -2.13870573,\n",
      "         -0.82343102,  0.12942110,  0.12823470, -0.26241016, -0.73390746,\n",
      "         -0.88948727, -2.24543715, -2.68738604, -0.15237324],\n",
      "        [-1.07683074, -0.53546339, -0.34234896, -0.67457855,  0.11810923,\n",
      "          1.49379814,  1.25420356,  1.33890092,  1.73831189,  1.82013714,\n",
      "          1.54024649,  0.92680019,  0.00106322,  1.04644692],\n",
      "        [-1.00096166, -0.16640256, -0.31145304, -0.15766668,  1.94367468,\n",
      "          3.15603805,  4.14216232,  2.71167684,  1.53689289,  2.20230103,\n",
      "          2.31037331,  1.53754020,  0.30175519,  2.34696317],\n",
      "        [-1.00081789, -0.17235930, -0.38537642,  1.33654213,  3.97253060,\n",
      "          4.52903795,  3.91571951, -0.14242339, -1.58178937, -0.63278455,\n",
      "          0.90158200,  0.92541975,  0.48232320,  2.14122987],\n",
      "        [-1.00104690, -0.36499995, -0.21707091,  2.16296124,  4.14147902,\n",
      "          5.20838547,  2.13414526, -2.73687339, -3.53820586, -3.96817946,\n",
      "         -2.47419810, -1.65149939, -1.16017377,  1.36187136],\n",
      "        [-1.00066650, -0.38593709,  0.20198102,  2.04827547,  4.32609653,\n",
      "          6.18273878,  2.97601509, -1.13123024, -0.00555202,  0.60720956,\n",
      "          0.35211483, -2.28498745, -0.91088444,  1.39609170],\n",
      "        [-1.00126970, -0.18869191,  0.14484321,  2.10440540,  4.02943802,\n",
      "          5.34647322,  0.66137940, -1.51651525,  1.46379626,  3.10602331,\n",
      "          2.49611950,  0.34036827, -1.77385974,  1.35330844],\n",
      "        [-1.00225604, -0.03247507, -0.09192856,  2.65098858,  2.89851189,\n",
      "          2.99480820,  0.62232870, -0.03616341,  0.81098741,  3.59480858,\n",
      "          2.52051163,  0.92481798, -0.71778303,  0.90971881],\n",
      "        [-1.00100398, -0.01468778, -0.37823683,  1.59408224,  2.81692123,\n",
      "          0.95600820, -1.25226331, -0.81410617, -0.27537325,  0.60421956,\n",
      "          1.41762269,  0.48595908,  0.32446387,  1.19435859],\n",
      "        [-1.00090134, -0.01678899,  0.02092926,  0.03732137,  1.03533423,\n",
      "          0.35448951,  0.65963948, -0.63150477,  2.00544310,  2.55580235,\n",
      "          1.73868346, -0.33487096,  0.19177103,  1.65709674],\n",
      "        [-0.58802807,  0.23979682,  0.65158957,  0.18231469,  0.82928085,\n",
      "          0.30162668,  1.49106622,  1.45170712,  3.08990383,  3.11185718,\n",
      "          0.84840465,  0.60119867,  0.25725946,  1.87007523],\n",
      "        [-1.00307107, -0.61713463, -0.36827454, -0.62634403, -1.14944100,\n",
      "         -1.35162532, -1.37011957, -0.08792242,  0.35044223,  1.00814641,\n",
      "         -0.33007064, -1.02116323, -1.45029259,  0.71004927],\n",
      "        [-0.01287339,  0.26360852,  0.49632195,  0.90997732,  0.47913361,\n",
      "          0.34465230, -0.60596031, -1.12406945, -0.97064108, -1.36866188,\n",
      "         -1.86185145, -1.19055092, -0.86405522,  0.75485873]])\n",
      "The output of last layer: Tensor(shape=[10], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [-0.31712723, -2.93327951,  0.11966074, -1.83170497,  0.11631604,\n",
      "         6.60023117,  5.08563900, -7.92927456,  4.14579010, -0.27252322]) \n",
      "\n",
      "Model has been saved.\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "# 定义模型结构\n",
    "class MNIST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "        \n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义一层全连接层，输出维度是10\n",
    "        self.fc = Linear(in_features=980, out_features=10)\n",
    "    \n",
    "    #加入对每一层输入和输出的尺寸和数据内容的打印，根据check参数决策是否打印每层的参数和输出尺寸\n",
    "    # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "    def forward(self, inputs, label=None, check_shape=False, check_content=False):\n",
    "        # 给不同层的输出不同命名，方便调试\n",
    "        outputs1 = self.conv1(inputs)\n",
    "        outputs2 = F.relu(outputs1)\n",
    "        outputs3 = self.max_pool1(outputs2)\n",
    "        outputs4 = self.conv2(outputs3)\n",
    "        outputs5 = F.relu(outputs4)\n",
    "        outputs6 = self.max_pool2(outputs5)\n",
    "        outputs6 = paddle.reshape(outputs6, [outputs6.shape[0], -1])\n",
    "        outputs7 = self.fc(outputs6)\n",
    "         \n",
    "        # 选择是否打印神经网络每层的参数尺寸和输出尺寸，验证网络结构是否设置正确\n",
    "        if check_shape:\n",
    "            # 打印每层网络设置的超参数-卷积核尺寸，卷积步长，卷积padding，池化核尺寸\n",
    "            print(\"\\n########## print network layer's superparams ##############\")\n",
    "            print(\"conv1-- kernel_size:{}, padding:{}, stride:{}\".format(self.conv1.weight.shape, self.conv1._padding, self.conv1._stride))\n",
    "            print(\"conv2-- kernel_size:{}, padding:{}, stride:{}\".format(self.conv2.weight.shape, self.conv2._padding, self.conv2._stride))\n",
    "            #print(\"max_pool1-- kernel_size:{}, padding:{}, stride:{}\".format(self.max_pool1.pool_size, self.max_pool1.pool_stride, self.max_pool1._stride))\n",
    "            #print(\"max_pool2-- kernel_size:{}, padding:{}, stride:{}\".format(self.max_pool2.weight.shape, self.max_pool2._padding, self.max_pool2._stride))\n",
    "            print(\"fc-- weight_size:{}, bias_size_{}\".format(self.fc.weight.shape, self.fc.bias.shape))\n",
    "            \n",
    "            # 打印每层的输出尺寸\n",
    "            print(\"\\n########## print shape of features of every layer ###############\")\n",
    "            print(\"inputs_shape: {}\".format(inputs.shape))\n",
    "            print(\"outputs1_shape: {}\".format(outputs1.shape))\n",
    "            print(\"outputs2_shape: {}\".format(outputs2.shape))\n",
    "            print(\"outputs3_shape: {}\".format(outputs3.shape))\n",
    "            print(\"outputs4_shape: {}\".format(outputs4.shape))\n",
    "            print(\"outputs5_shape: {}\".format(outputs5.shape))\n",
    "            print(\"outputs6_shape: {}\".format(outputs6.shape))\n",
    "            print(\"outputs7_shape: {}\".format(outputs7.shape))\n",
    "            # print(\"outputs8_shape: {}\".format(outputs8.shape))\n",
    "            \n",
    "        # 选择是否打印训练过程中的参数和输出内容，可用于训练过程中的调试\n",
    "        if check_content:\n",
    "           # 打印卷积层的参数-卷积核权重，权重参数较多，此处只打印部分参数\n",
    "            print(\"\\n########## print convolution layer's kernel ###############\")\n",
    "            print(\"conv1 params -- kernel weights:\", self.conv1.weight[0][0])\n",
    "            print(\"conv2 params -- kernel weights:\", self.conv2.weight[0][0])\n",
    "\n",
    "             # 创建随机数，随机打印某一个通道的输出值\n",
    "            idx1 = np.random.randint(0, outputs1.shape[1])\n",
    "            idx2 = np.random.randint(0, outputs4.shape[1])\n",
    "            # 打印卷积-池化后的结果，仅打印batch中第一个图像对应的特征\n",
    "            print(\"\\nThe {}th channel of conv1 layer: \".format(idx1), outputs1[0][idx1])\n",
    "            print(\"The {}th channel of conv2 layer: \".format(idx2), outputs4[0][idx2])\n",
    "            print(\"The output of last layer:\", outputs7[0], '\\n')\n",
    "            \n",
    "        # 如果label不是None，则计算分类精度并返回\n",
    "        if label is not None:\n",
    "            acc = paddle.metric.accuracy(input=F.softmax(outputs7), label=label)\n",
    "            return outputs7, acc\n",
    "        else:\n",
    "            return outputs7\n",
    "\n",
    "#在使用GPU机器时，可以将use_gpu变量设置成True\n",
    "use_gpu = True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')    \n",
    "\n",
    "def train(model):\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    \n",
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Momentum(learning_rate=0.01, momentum=0.9, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 1\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            if batch_id == 0 and epoch_id==0:\n",
    "                # 打印模型参数和每层输出的尺寸\n",
    "                predicts, acc = model(images, labels, check_shape=True, check_content=False)\n",
    "            elif batch_id==401:\n",
    "                # 打印模型参数和每层输出的值\n",
    "                predicts, acc = model(images, labels, check_shape=False, check_content=True)\n",
    "            else:\n",
    "                predicts, acc = model(images, labels)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist_test.pdparams')\n",
    "    \n",
    "#创建模型    \n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)\n",
    "\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入校验或测试，更好评价模型效果 \n",
    "\n",
    "在训练过程中，我们会发现模型在训练样本集上的损失在不断减小。但这是否代表模型在未来的应用场景上依然有效？为了验证模型的有效性，通常将样本集合分成三份，训练集、校验集和测试集。\n",
    "\n",
    "- **训练集** ：用于训练模型的参数，即训练过程中主要完成的工作。\n",
    "- **校验集** ：用于对模型超参数的选择，比如网络结构的调整、正则化项权重的选择等。\n",
    "- **测试集** ：用于模拟模型在应用后的真实效果。因为测试集没有参与任何模型优化或参数训练的工作，所以它对模型来说是完全未知的样本。在不以校验数据优化网络结构或模型超参数时，校验数据和测试数据的效果是类似的，均更真实的反映模型效果。\n",
    "\n",
    "如下程序读取上一步训练保存的模型参数，读取校验数据集，并测试模型在校验数据集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluation .......\n",
      "loading mnist dataset from ./work/mnist.json.gz ......\n",
      "loss=0.07362690851441585, acc=0.976400004029274\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model):\n",
    "    print('start evaluation .......')\n",
    "    # 定义预测过程\n",
    "    params_file_path = 'mnist.pdparams'\n",
    "    # 加载模型参数\n",
    "    param_dict = paddle.load(params_file_path)\n",
    "    model.load_dict(param_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = load_data('eval')\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        predicts, acc = model(images, labels)\n",
    "        loss = F.cross_entropy(input=predicts, label=labels)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    \n",
    "    #计算多个batch的平均损失和准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "model = MNIST()\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从测试的效果来看，模型在验证集上依然有98.6%的准确率，证明它是有预测效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入正则化项，避免模型过拟合\n",
    "   \n",
    "## 过拟合现象\n",
    "\n",
    "对于样本量有限、但需要使用强大模型的复杂任务，模型很容易出现过拟合的表现，即在训练集上的损失小，在验证集或测试集上的损失较大，如 **图2** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/99b879c21113494a9d7315eeda74bc4c8fea07f984824a03bf8411e946c75f1b\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图2：过拟合现象，训练误差不断降低，但测试误差先降后增</br></center>\n",
    "<br></br>\n",
    "\n",
    "反之，如果模型在训练集和测试集上均损失较大，则称为欠拟合。过拟合表示模型过于敏感，学习到了训练数据中的一些误差，而这些误差并不是真实的泛化规律（可推广到测试集上的规律）。欠拟合表示模型还不够强大，还没有很好的拟合已知的训练样本，更别提测试样本了。因为欠拟合情况容易观察和解决，只要训练loss不够好，就不断使用更强大的模型即可，因此实际中我们更需要处理好过拟合的问题。\n",
    "\n",
    "## 导致过拟合原因\n",
    "\n",
    "造成过拟合的原因是模型过于敏感，而训练数据量太少或其中的噪音太多。\n",
    "\n",
    "如**图3** 所示，理想的回归模型是一条坡度较缓的抛物线，欠拟合的模型只拟合出一条直线，显然没有捕捉到真实的规律，但过拟合的模型拟合出存在很多拐点的抛物线，显然是过于敏感，也没有正确表达真实规律。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/53c389bb3c824706bd2fbc05f83ab0c6dd6b5b2fdedb4150a17e16a1b64c243e\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图3：回归模型的过拟合，理想和欠拟合状态的表现</br></center>\n",
    "<br></br>\n",
    "\n",
    "如**图4** 所示，理想的分类模型是一条半圆形的曲线，欠拟合用直线作为分类边界，显然没有捕捉到真实的边界，但过拟合的模型拟合出很扭曲的分类边界，虽然对所有的训练数据正确分类，但对一些较为个例的样本所做出的妥协，高概率不是真实的规律。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/b5a46f7e0fbe4f8686a71d9a2d330ed09f23bca565a44e0d941148729fd2f7d7\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图4：分类模型的欠拟合，理想和过拟合状态的表现</br></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过拟合的成因与防控\n",
    "\n",
    "为了更好的理解过拟合的成因，可以参考侦探定位罪犯的案例逻辑，如 **图5** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/34de60a675b64468a2c3fee0844a168d53e891eaacf643fd8c1c9ba8e3812bcc\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图5：侦探定位罪犯与模型假设示意</br></center>\n",
    "<br></br>\n",
    "\n",
    "**对于这个案例，假设侦探也会犯错，通过分析发现可能的原因：**\n",
    "\n",
    "1. 情况1：罪犯证据存在错误，依据错误的证据寻找罪犯肯定是缘木求鱼。\n",
    "\n",
    "2. 情况2：搜索范围太大的同时证据太少，导致符合条件的候选（嫌疑人）太多，无法准确定位罪犯。\n",
    "\n",
    "**那么侦探解决这个问题的方法有两种：或者缩小搜索范围（比如假设该案件只能是熟人作案），或者寻找更多的证据。**\n",
    "\n",
    "**归结到深度学习中，假设模型也会犯错，通过分析发现可能的原因：**\n",
    "\n",
    "1. 情况1：训练数据存在噪音，导致模型学到了噪音，而不是真实规律。\n",
    "\n",
    "2. 情况2：使用强大模型（表示空间大）的同时训练数据太少，导致在训练数据上表现良好的候选假设太多，锁定了一个“虚假正确”的假设。\n",
    "\n",
    "**对于情况1，我们使用数据清洗和修正来解决。 对于情况2，我们或者限制模型表示能力，或者收集更多的训练数据。**\n",
    "\n",
    "而清洗训练数据中的错误，或收集更多的训练数据往往是一句“正确的废话”，在任何时候我们都想获得更多更高质量的数据。在实际项目中，更快、更低成本可控制过拟合的方法，只有限制模型的表示能力。\n",
    "\n",
    "## 正则化项\n",
    "\n",
    "为了防止模型过拟合，在没有扩充样本量的可能下，只能降低模型的复杂度，可以通过限制参数的数量或可能取值（参数值尽量小）实现。\n",
    "\n",
    "具体来说，在模型的优化目标（损失）中人为加入对参数规模的惩罚项。当参数越多或取值越大时，该惩罚项就越大。通过调整惩罚项的权重系数，可以使模型在“尽量减少训练损失”和“保持模型的泛化能力”之间取得平衡。泛化能力表示模型在没有见过的样本上依然有效。正则化项的存在，增加了模型在训练集上的损失。\n",
    "\n",
    "飞桨支持为所有参数加上统一的正则化项，也支持为特定的参数添加正则化项。前者的实现如下代码所示，仅在优化器中设置``weight_decay``参数即可实现。使用参数``coeff``调节正则化项的权重，权重越大时，对模型复杂度的惩罚越高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: 3.8336219787597656, acc is 0.12999999523162842\n",
      "epoch: 0, batch: 200, loss is: 0.13598236441612244, acc is 0.9700000286102295\n",
      "epoch: 0, batch: 400, loss is: 0.25560829043388367, acc is 0.9399999976158142\n",
      "epoch: 1, batch: 0, loss is: 0.1124507263302803, acc is 0.9599999785423279\n",
      "epoch: 1, batch: 200, loss is: 0.15530556440353394, acc is 0.9599999785423279\n",
      "epoch: 1, batch: 400, loss is: 0.043170083314180374, acc is 0.9800000190734863\n",
      "epoch: 2, batch: 0, loss is: 0.0213349349796772, acc is 1.0\n",
      "epoch: 2, batch: 200, loss is: 0.031207630410790443, acc is 0.9900000095367432\n",
      "epoch: 2, batch: 400, loss is: 0.1240094006061554, acc is 0.9700000286102295\n",
      "epoch: 3, batch: 0, loss is: 0.02936435677111149, acc is 0.9900000095367432\n",
      "epoch: 3, batch: 200, loss is: 0.06728698313236237, acc is 0.9700000286102295\n",
      "epoch: 3, batch: 400, loss is: 0.0212791096419096, acc is 1.0\n",
      "epoch: 4, batch: 0, loss is: 0.044868700206279755, acc is 0.9700000286102295\n",
      "epoch: 4, batch: 200, loss is: 0.03535199537873268, acc is 0.9900000095367432\n",
      "epoch: 4, batch: 400, loss is: 0.025770850479602814, acc is 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "def train(model):\n",
    "    model.train() \n",
    "\n",
    "    #各种优化算法均可以加入正则化项，避免过拟合，参数regularization_coeff调节正则化项的权重\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.01, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5), parameters=model.parameters())           \n",
    "\n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predicts, acc = model(images, labels)\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist_regul.pdparams')\n",
    "\n",
    "model = MNIST()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluation .......\n",
      "loading mnist dataset from ./work/mnist.json.gz ......\n",
      "loss=0.08833945716934977, acc=0.974200005531311\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model):\n",
    "    print('start evaluation .......')\n",
    "    # 定义预测过程\n",
    "    params_file_path = 'mnist_regul.pdparams'\n",
    "    # 加载模型参数\n",
    "    param_dict = paddle.load(params_file_path)\n",
    "    model.load_dict(param_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = load_data('eval')\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        predicts, acc = model(images, labels)\n",
    "        loss = F.cross_entropy(input=predicts, label=labels)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    \n",
    "    #计算多个batch的平均损失和准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "model = MNIST()\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化分析\n",
    "\n",
    "训练模型时，经常需要观察模型的评价指标，分析模型的优化过程，以确保训练是有效的。可选用这两种工具：Matplotlib库和VisualDL。\n",
    "\n",
    "* **Matplotlib库**：Matplotlib库是Python中使用的最多的2D图形绘图库，它有一套完全仿照MATLAB的函数形式的绘图接口，使用轻量级的PLT库（Matplotlib）作图是非常简单的。\n",
    "* **VisualDL**：如果期望使用更加专业的作图工具，可以尝试VisualDL，飞桨可视化分析工具。VisualDL能够有效地展示飞桨在运行过程中的计算图、各种指标变化趋势和数据信息。\n",
    "\n",
    "## 使用Matplotlib库绘制损失随训练下降的曲线图\n",
    "\n",
    "将训练的批次编号作为X轴坐标，该批次的训练损失作为Y轴坐标。\n",
    "\n",
    "1. 训练开始前，声明两个列表变量存储对应的批次编号(iters=[])和训练损失(losses=[])。\n",
    "```\n",
    "iters=[]\n",
    "losses=[]\n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "\t\"\"\"start to training\"\"\"\n",
    "```\n",
    "\n",
    "2. 随着训练的进行，将iter和losses两个列表填满。\n",
    "```\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "iters=[]\n",
    "losses=[]\n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "\tfor batch_id, data in enumerate(train_loader()):\n",
    "        images, labels = data\n",
    "        predicts, acc = model(images, labels)\n",
    "        loss = F.cross_entropy(predicts, label = labels.astype('int64'))\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        # 累计迭代次数和对应的loss\n",
    "   \titers.append(batch_id + epoch_id*len(list(train_loader()))\n",
    "\tlosses.append(avg_loss)\n",
    "```\n",
    "\n",
    "3. 训练结束后，将两份数据以参数形式导入PLT的横纵坐标。\n",
    "```\n",
    "plt.xlabel(\"iter\", fontsize=14)，plt.ylabel(\"loss\", fontsize=14)\n",
    "```\n",
    "4. 最后，调用plt.plot()函数即可完成作图。\n",
    "```\n",
    "plt.plot(iters, losses,color='red',label='train loss') \n",
    "```\n",
    "\n",
    "详细代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: 2.9369280338287354, acc is 0.10999999940395355\n",
      "epoch: 0, batch: 100, loss is: 0.367893248796463, acc is 0.8899999856948853\n",
      "epoch: 0, batch: 200, loss is: 0.07098619639873505, acc is 0.9800000190734863\n",
      "epoch: 0, batch: 300, loss is: 0.2564907968044281, acc is 0.8999999761581421\n",
      "epoch: 0, batch: 400, loss is: 0.12164297699928284, acc is 0.9700000286102295\n",
      "epoch: 1, batch: 0, loss is: 0.07896294444799423, acc is 0.9700000286102295\n",
      "epoch: 1, batch: 100, loss is: 0.07898575812578201, acc is 0.9900000095367432\n",
      "epoch: 1, batch: 200, loss is: 0.09822852164506912, acc is 0.9399999976158142\n",
      "epoch: 1, batch: 300, loss is: 0.08663148432970047, acc is 0.9599999785423279\n",
      "epoch: 1, batch: 400, loss is: 0.06954633444547653, acc is 0.9800000190734863\n",
      "epoch: 2, batch: 0, loss is: 0.10620040446519852, acc is 0.9900000095367432\n",
      "epoch: 2, batch: 100, loss is: 0.1543780118227005, acc is 0.9599999785423279\n",
      "epoch: 2, batch: 200, loss is: 0.06949719041585922, acc is 0.9800000190734863\n",
      "epoch: 2, batch: 300, loss is: 0.05012770742177963, acc is 0.9900000095367432\n",
      "epoch: 2, batch: 400, loss is: 0.03557739406824112, acc is 0.9900000095367432\n",
      "epoch: 3, batch: 0, loss is: 0.033731862902641296, acc is 0.9900000095367432\n",
      "epoch: 3, batch: 100, loss is: 0.0712876096367836, acc is 0.9800000190734863\n",
      "epoch: 3, batch: 200, loss is: 0.039561446756124496, acc is 0.9900000095367432\n",
      "epoch: 3, batch: 300, loss is: 0.046025730669498444, acc is 0.9800000190734863\n",
      "epoch: 3, batch: 400, loss is: 0.0252643134444952, acc is 0.9800000190734863\n",
      "epoch: 4, batch: 0, loss is: 0.07395735383033752, acc is 0.9800000190734863\n",
      "epoch: 4, batch: 100, loss is: 0.06321269273757935, acc is 0.9900000095367432\n",
      "epoch: 4, batch: 200, loss is: 0.053525373339653015, acc is 0.9599999785423279\n",
      "epoch: 4, batch: 300, loss is: 0.006580906454473734, acc is 1.0\n",
      "epoch: 4, batch: 400, loss is: 0.029692480340600014, acc is 0.9900000095367432\n",
      "epoch: 5, batch: 0, loss is: 0.03267919644713402, acc is 0.9900000095367432\n",
      "epoch: 5, batch: 100, loss is: 0.03511189669370651, acc is 0.9900000095367432\n",
      "epoch: 5, batch: 200, loss is: 0.027216214686632156, acc is 0.9900000095367432\n",
      "epoch: 5, batch: 300, loss is: 0.04068734869360924, acc is 0.9700000286102295\n",
      "epoch: 5, batch: 400, loss is: 0.0043058330193161964, acc is 1.0\n",
      "epoch: 6, batch: 0, loss is: 0.001718524843454361, acc is 1.0\n",
      "epoch: 6, batch: 100, loss is: 0.007522453088313341, acc is 1.0\n",
      "epoch: 6, batch: 200, loss is: 0.01958162896335125, acc is 0.9900000095367432\n",
      "epoch: 6, batch: 300, loss is: 0.03562464937567711, acc is 0.9800000190734863\n",
      "epoch: 6, batch: 400, loss is: 0.011984555050730705, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 0, loss is: 0.01842007227241993, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 100, loss is: 0.11087141931056976, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 200, loss is: 0.013940869830548763, acc is 1.0\n",
      "epoch: 7, batch: 300, loss is: 0.03091098554432392, acc is 0.9800000190734863\n",
      "epoch: 7, batch: 400, loss is: 0.0014108731411397457, acc is 1.0\n",
      "epoch: 8, batch: 0, loss is: 0.0032317908480763435, acc is 1.0\n",
      "epoch: 8, batch: 100, loss is: 0.0005690905964002013, acc is 1.0\n",
      "epoch: 8, batch: 200, loss is: 0.00526630412787199, acc is 1.0\n",
      "epoch: 8, batch: 300, loss is: 0.0157221220433712, acc is 1.0\n",
      "epoch: 8, batch: 400, loss is: 0.03185774013400078, acc is 0.9800000190734863\n",
      "epoch: 9, batch: 0, loss is: 0.01022623386234045, acc is 1.0\n",
      "epoch: 9, batch: 100, loss is: 0.001588689861819148, acc is 1.0\n",
      "epoch: 9, batch: 200, loss is: 0.0015124892815947533, acc is 1.0\n",
      "epoch: 9, batch: 300, loss is: 0.009973852895200253, acc is 0.9900000095367432\n",
      "epoch: 9, batch: 400, loss is: 0.0016880237963050604, acc is 1.0\n"
     ]
    }
   ],
   "source": [
    "#引入matplotlib库\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    \n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 10\n",
    "    iter=0\n",
    "    iters=[]\n",
    "    losses=[]\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predicts, acc = model(images, labels)\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "                iters.append(iter)\n",
    "                losses.append(avg_loss.numpy())\n",
    "                iter = iter + 100\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            \n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "    return iters, losses\n",
    "    \n",
    "model = MNIST()\n",
    "iters, losses = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画出训练过程中Loss的变化曲线\n",
    "plt.figure()\n",
    "plt.title(\"train loss\", fontsize=24)\n",
    "plt.xlabel(\"iter\", fontsize=14)\n",
    "plt.ylabel(\"loss\", fontsize=14)\n",
    "plt.plot(iters, losses,color='red',label='train loss') \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用VisualDL可视化分析\n",
    "\n",
    "VisualDL是飞桨可视化分析工具，以丰富的图表呈现训练参数变化趋势、模型结构、数据样本、高维数据分布等。帮助用户清晰直观地理解深度学习模型训练过程及模型结构，进而实现高效的模型调优，具体代码实现如下。\n",
    "\n",
    "* 步骤1：引入VisualDL库，定义作图数据存储位置（供第3步使用），本案例的路径是“log”。\n",
    "```\n",
    "from visualdl import LogWriter\n",
    "log_writer = LogWriter(\"./log\")\n",
    "```\n",
    "* 步骤2：在训练过程中插入作图语句。当每100个batch训练完成后，将当前损失作为一个新增的数据点(iter和acc的映射对)存储到第一步设置的文件中。使用变量iter记录下已经训练的批次数，作为作图的X轴坐标。\n",
    "\n",
    "```\n",
    "log_writer.add_scalar(tag = 'acc', step = iter, value = avg_acc.numpy())\n",
    "log_writer.add_scalar(tag = 'loss', step = iter, value = avg_loss.numpy())\n",
    "iter = iter + 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: visualdl in /root/.local/lib/python3.8/site-packages (2.5.3)\n",
      "Requirement already satisfied: bce-python-sdk in /root/.local/lib/python3.8/site-packages (from visualdl) (0.8.98)\n",
      "Requirement already satisfied: flask>=1.1.1 in /root/.local/lib/python3.8/site-packages (from visualdl) (3.0.0)\n",
      "Requirement already satisfied: Flask-Babel>=3.0.0 in /root/.local/lib/python3.8/site-packages (from visualdl) (4.0.0)\n",
      "Requirement already satisfied: numpy in /root/.local/lib/python3.8/site-packages (from visualdl) (1.24.4)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /root/.local/lib/python3.8/site-packages (from visualdl) (10.1.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /root/miniconda3/envs/paddle_learn/lib/python3.8/site-packages (from visualdl) (4.25.1)\n",
      "Requirement already satisfied: requests in /root/.local/lib/python3.8/site-packages (from visualdl) (2.31.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /root/.local/lib/python3.8/site-packages (from visualdl) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /root/.local/lib/python3.8/site-packages (from visualdl) (3.7.4)\n",
      "Requirement already satisfied: pandas in /root/.local/lib/python3.8/site-packages (from visualdl) (2.0.3)\n",
      "Requirement already satisfied: packaging in /root/.local/lib/python3.8/site-packages (from visualdl) (23.2)\n",
      "Requirement already satisfied: rarfile in /root/.local/lib/python3.8/site-packages (from visualdl) (4.1)\n",
      "Requirement already satisfied: psutil in /root/.local/lib/python3.8/site-packages (from visualdl) (5.9.7)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /root/.local/lib/python3.8/site-packages (from flask>=1.1.1->visualdl) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /root/.local/lib/python3.8/site-packages (from flask>=1.1.1->visualdl) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /root/.local/lib/python3.8/site-packages (from flask>=1.1.1->visualdl) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /root/.local/lib/python3.8/site-packages (from flask>=1.1.1->visualdl) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /root/.local/lib/python3.8/site-packages (from flask>=1.1.1->visualdl) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /root/.local/lib/python3.8/site-packages (from flask>=1.1.1->visualdl) (7.0.1)\n",
      "Requirement already satisfied: Babel>=2.12 in /root/.local/lib/python3.8/site-packages (from Flask-Babel>=3.0.0->visualdl) (2.14.0)\n",
      "Requirement already satisfied: pytz>=2022.7 in /root/.local/lib/python3.8/site-packages (from Flask-Babel>=3.0.0->visualdl) (2023.3.post1)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /root/.local/lib/python3.8/site-packages (from bce-python-sdk->visualdl) (3.19.0)\n",
      "Requirement already satisfied: future>=0.6.0 in /root/.local/lib/python3.8/site-packages (from bce-python-sdk->visualdl) (0.18.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /root/.local/lib/python3.8/site-packages (from matplotlib->visualdl) (6.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/.local/lib/python3.8/site-packages (from pandas->visualdl) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.local/lib/python3.8/site-packages (from requests->visualdl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.8/site-packages (from requests->visualdl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.8/site-packages (from requests->visualdl) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.8/site-packages (from requests->visualdl) (2023.11.17)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/.local/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask>=1.1.1->visualdl) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask>=1.1.1->visualdl) (2.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 安装VisualDL\n",
    "!pip install --upgrade --pre visualdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: 4.268248558044434, acc is 0.09000000357627869\n",
      "epoch: 0, batch: 100, loss is: 0.2475145161151886, acc is 0.9300000071525574\n",
      "epoch: 0, batch: 200, loss is: 0.21958422660827637, acc is 0.9399999976158142\n",
      "epoch: 0, batch: 300, loss is: 0.18018056452274323, acc is 0.9599999785423279\n",
      "epoch: 0, batch: 400, loss is: 0.09924077242612839, acc is 0.9800000190734863\n",
      "epoch: 1, batch: 0, loss is: 0.07932081818580627, acc is 0.9800000190734863\n",
      "epoch: 1, batch: 100, loss is: 0.10599736124277115, acc is 0.949999988079071\n",
      "epoch: 1, batch: 200, loss is: 0.026834527030587196, acc is 1.0\n",
      "epoch: 1, batch: 300, loss is: 0.11744561791419983, acc is 0.9300000071525574\n",
      "epoch: 1, batch: 400, loss is: 0.07028964161872864, acc is 0.9800000190734863\n",
      "epoch: 2, batch: 0, loss is: 0.04242385923862457, acc is 0.9900000095367432\n",
      "epoch: 2, batch: 100, loss is: 0.04738432914018631, acc is 0.9900000095367432\n",
      "epoch: 2, batch: 200, loss is: 0.06059197336435318, acc is 0.9800000190734863\n",
      "epoch: 2, batch: 300, loss is: 0.05576532334089279, acc is 0.9800000190734863\n",
      "epoch: 2, batch: 400, loss is: 0.023292288184165955, acc is 0.9900000095367432\n",
      "epoch: 3, batch: 0, loss is: 0.0174590852111578, acc is 1.0\n",
      "epoch: 3, batch: 100, loss is: 0.11666563898324966, acc is 0.9700000286102295\n",
      "epoch: 3, batch: 200, loss is: 0.005619326140731573, acc is 1.0\n",
      "epoch: 3, batch: 300, loss is: 0.04803198575973511, acc is 0.9900000095367432\n",
      "epoch: 3, batch: 400, loss is: 0.037978459149599075, acc is 0.9800000190734863\n",
      "epoch: 4, batch: 0, loss is: 0.03315560519695282, acc is 0.9900000095367432\n",
      "epoch: 4, batch: 100, loss is: 0.05371325835585594, acc is 0.9800000190734863\n",
      "epoch: 4, batch: 200, loss is: 0.08208803087472916, acc is 0.9599999785423279\n",
      "epoch: 4, batch: 300, loss is: 0.0671887993812561, acc is 0.9800000190734863\n",
      "epoch: 4, batch: 400, loss is: 0.026759514585137367, acc is 0.9900000095367432\n",
      "epoch: 5, batch: 0, loss is: 0.032436516135931015, acc is 0.9800000190734863\n",
      "epoch: 5, batch: 100, loss is: 0.004638053476810455, acc is 1.0\n",
      "epoch: 5, batch: 200, loss is: 0.06799077242612839, acc is 0.9900000095367432\n",
      "epoch: 5, batch: 300, loss is: 0.04532613977789879, acc is 0.9800000190734863\n",
      "epoch: 5, batch: 400, loss is: 0.06378643959760666, acc is 0.9700000286102295\n",
      "epoch: 6, batch: 0, loss is: 0.012179736979305744, acc is 1.0\n",
      "epoch: 6, batch: 100, loss is: 0.004188894759863615, acc is 1.0\n",
      "epoch: 6, batch: 200, loss is: 0.018959909677505493, acc is 0.9900000095367432\n",
      "epoch: 6, batch: 300, loss is: 0.06784170866012573, acc is 0.9599999785423279\n",
      "epoch: 6, batch: 400, loss is: 0.007025245111435652, acc is 1.0\n",
      "epoch: 7, batch: 0, loss is: 0.011962958611547947, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 100, loss is: 0.05342382192611694, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 200, loss is: 0.027685675770044327, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 300, loss is: 0.0215607937425375, acc is 0.9900000095367432\n",
      "epoch: 7, batch: 400, loss is: 0.004059449769556522, acc is 1.0\n",
      "epoch: 8, batch: 0, loss is: 0.018151158466935158, acc is 0.9900000095367432\n",
      "epoch: 8, batch: 100, loss is: 0.004287974908947945, acc is 1.0\n",
      "epoch: 8, batch: 200, loss is: 0.0007043275982141495, acc is 1.0\n",
      "epoch: 8, batch: 300, loss is: 0.0024667505640536547, acc is 1.0\n",
      "epoch: 8, batch: 400, loss is: 0.0009784174617379904, acc is 1.0\n",
      "epoch: 9, batch: 0, loss is: 0.011825093999505043, acc is 1.0\n",
      "epoch: 9, batch: 100, loss is: 0.011021094396710396, acc is 1.0\n",
      "epoch: 9, batch: 200, loss is: 0.014034098014235497, acc is 0.9900000095367432\n",
      "epoch: 9, batch: 300, loss is: 0.01580997183918953, acc is 0.9900000095367432\n",
      "epoch: 9, batch: 400, loss is: 0.0075181047432124615, acc is 1.0\n"
     ]
    }
   ],
   "source": [
    "#引入VisualDL库，并设定保存作图数据的文件位置\n",
    "from visualdl import LogWriter\n",
    "log_writer = LogWriter(logdir=\"./log\")\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    \n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 10\n",
    "    iter = 0\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predicts, avg_acc = model(images, labels)\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), avg_acc.numpy()))\n",
    "                log_writer.add_scalar(tag = 'acc', step = iter, value = avg_acc.numpy())\n",
    "                log_writer.add_scalar(tag = 'loss', step = iter, value = avg_loss.numpy())\n",
    "                iter = iter + 100\n",
    "\n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "model = MNIST()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 步骤3：命令行启动VisualDL。\n",
    "\n",
    "使用“visualdl --logdir [数据文件所在文件夹路径] 的命令启动VisualDL。在VisualDL启动后，命令行会打印出可用浏览器查阅图形结果的网址。\n",
    "``` \n",
    "$ visualdl --logdir ./log --port 8080\n",
    "```\n",
    "\n",
    "* 步骤4：打开浏览器，查看作图结果，如 **图6** 所示。\n",
    "\n",
    "查阅的网址在第三步的启动命令后会打印出来（如http://127.0.0.1:8080/），将该网址输入浏览器地址栏刷新页面的效果如下图所示。除了右侧对数据点的作图外，左侧还有一个控制板，可以调整诸多作图的细节。\n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/c29fdeed4f404eeb846c8c864497f939b5920c3e6fea4f60a9e4ebe4503b6a6b\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图6：VisualDL作图示例</br></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业题\n",
    "\n",
    "* 将普通神经网络模型的每层输出打印，观察内容。\n",
    "* 将分类准确率的指标 用PLT库画图表示。\n",
    "* 通过分类准确率，判断以采用不同损失函数训练模型的效果优劣。\n",
    "* 作图比较：随着训练进行，模型在训练集和测试集上的Loss曲线。\n",
    "* 调节正则化权重，观察4的作图曲线的变化，并分析原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次预测的数字是:  8\n"
     ]
    }
   ],
   "source": [
    "# 读取一张本地的样例图片，转变成模型输入的格式\n",
    "def load_image(img_path):\n",
    "    # 从img_path中读取图像，并转为灰度图\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    im = im.resize((28, 28), Image.LANCZOS)\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)\n",
    "    # 图像归一化\n",
    "    im = 1.0 - im / 255.\n",
    "    return im\n",
    "\n",
    "# 定义预测过程\n",
    "model = MNIST()\n",
    "params_file_path = 'mnist.pdparams'\n",
    "img_path = 'work/example_7.jpg'\n",
    "# 加载模型参数\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "# 灌入数据\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "#模型反馈10个分类标签的对应概率\n",
    "results = model(paddle.to_tensor(tensor_img))\n",
    "#取概率最大的标签作为预测输出\n",
    "lab = np.argsort(results.numpy())\n",
    "print(\"本次预测的数字是: \", lab[0][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
